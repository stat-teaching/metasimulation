{
  "hash": "63683e24b66dab65c3bcfc0f377b6f35",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Power analysis\"\n---\n\n\n\n\n\n\n# Statistical Power {.section}\n\n## Power in a nutshell^[Thanks to https://rpsychologist.com/creating-a-typical-textbook-illustration-of-statistical-power-using-either-ggplot-or-base-graphics]\n\nThe stastistical power is defined as the probability of correctly rejecting the null hypothesis $H_0$.\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](power-analysis_files/figure-revealjs/unnamed-chunk-3-1.svg){fig-align='center' width=960}\n:::\n:::\n\n\n## Power in a nutshell\n\nFor simple designs such as t-test, ANOVA, etc. the power can be computed analytically. For example, let's find the power of detecting an effect size of $d = 0.5$ with $n1 = n2 = 30$.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nd <- 0.5\nalpha <- 0.05\nn1 <- n2 <- 30\nsp <- 1\n\n# Calculate non-centrality parameter (delta)\ndelta <- d * sqrt(n1 * n2 / (n1 + n2))\n\n# Calculate degrees of freedom\ndf <- n1 + n2 - 2\n\n# Calculate critical t-value\ncritical_t <- qt(1 - alpha / 2, df)\n\n# Calculate non-central t-distribution value\nnon_central_t <- delta / sp\n\n# Calculate power\n1 - pt(critical_t - non_central_t, df)\n#> [1] 0.4741093\n```\n:::\n\n\n## Power in a nutshell\n\nThe same can be done using the `pwr` package:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\npower <- pwr::pwr.t.test(n = n1, d = 0.5)\npower\n#> \n#>      Two-sample t test power calculation \n#> \n#>               n = 30\n#>               d = 0.5\n#>       sig.level = 0.05\n#>           power = 0.4778965\n#>     alternative = two.sided\n#> \n#> NOTE: n is number in *each* group\n```\n:::\n\n\n## Power in a nutshell\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](power-analysis_files/figure-revealjs/unnamed-chunk-6-1.svg){fig-align='center' width=960}\n:::\n:::\n\n\n## Power by simulations\n\nSometimes the analytical solution is not available or we can estimate the power for complex scenarios (missing data, unequal variances, etc.). The general workflow is:\n\n1. Generate data under the parametric assumptions\n2. Fit the appropriate model\n3. Extract the relevant metric (e.g., p-value)\n4. Repeat 1-3 several times (1000, 10000 or more)\n5. Summarise the results\n\nFor example, the power is the number of p-values lower than $\\alpha$ over the total number of simulations.\n\n## Power by simulations\n\nLet's see the previous example using simulations:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nnsim <- 5000\np <- rep(NA, nsim)\nfor(i in 1:nsim){\n    g1 <- rnorm(n1, 0, 1)\n    g2 <- rnorm(n2, d, 1)\n    p[i] <- t.test(g1, g2)$p.value\n}\nmean(p <= alpha)\n#> [1] 0.4798\n```\n:::\n\n\nThe estimated value is pretty close to the analytical value.\n\n## What about meta-analysis\n\nAlso for meta-analysis we have the two approaches analytical and simulation-based.\n\n- The analytical approach for (intercept-only) random-effects and equal-effects model can be found on @Borenstein2009-mo (Chapter 29). See also @Valentine2010-aj and @Hedges2001-ra\n- @Jackson2017-dv proposed a similar but improved approach\n\n## Analytical approach\n\nFor the analytical approach we need to make some assumptions:\n\n- $\\tau^2$ and $\\mu_{\\theta}$ (or $\\theta$) are estimated without errors\n- The $\\sigma^2_i$ (thus the sample size) of each $k$ study is the same\n\nUnder these assumptions the power is:\n\n$$\n(1 - \\Phi(c_{\\alpha} - \\lambda)) + \\Phi(-c_{\\alpha} - \\lambda)\n$$\n\nWhere $c_{\\alpha}$ is the critical $z$ value and $\\lambda$ is the observed statistics.\n\n## Analytical approach - EE model\n\nFor an EE model the only source of variability is the sampling variability, thus $\\lambda$:\n\n$$\n\\lambda_{EE} = \\frac{\\theta}{\\sqrt{\\sigma^2_{\\theta}}}\n$$\n\nAnd recalling previous assuptions where $\\sigma^2_1 = \\dots = \\sigma^2_k$:\n\n$$\n\\sigma^2_{\\theta} = \\frac{\\sigma^2}{k}\n$$\n\n## Analytical approach - EE model\n\nFor example, a meta-analysis of $k = 15$ studies where each study have a sample size of $n1 = n2 = 20$ (assuming again unstandardized mean difference as effect size):\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nk <- 10\ntheta <- 0.3\nn1 <- n2 <- 25\nvt <- 1/n1 + 1/n2\nvtheta <- vt/k\nlambda <- theta/sqrt(vtheta)\nzcrit <- abs(qnorm(0.05/2))\n(1 - pnorm(zcrit - lambda)) + pnorm(-zcrit - lambda)\n#> [1] 0.9183621\n```\n:::\n\n\nBe careful that the EE model is assuming $\\tau^2 = 0$ thus is like having a huge study with $k \\times n_1$ participants per group.\n\n## Analytical approach - RE model\n\nFor the RE model we just need to include $\\tau^2$ in the $\\lambda$ calculation, thus:\n\n$$\n\\sigma^{2\\star}_{\\theta} = \\frac{\\sigma^2 + \\tau^2}{k}\n$$\n\nThe other calculations are the same as the EE model.\n\n## Analytical approach - RE model\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nk <- 10\nmu <- 0.3\ntau2 <- 0.1\nn1 <- n2 <- 25\nvt <- 1/n1 + 1/n2\nvtheta <- (vt + tau2)/k\nlambda <- mu/sqrt(vtheta)\nzcrit <- abs(qnorm(0.05/2))\n(1 - pnorm(zcrit - lambda)) + pnorm(-zcrit - lambda)\n#> [1] 0.6087795\n```\n:::\n\n\nThe power is reduced because we are considering another source of heterogeneity. Clearly the maximal power of $k$ studies is achieved when $\\tau^2 = 0$. Hypothetically we can increase the power either increasing $k$ (the number of studies) or reducing $\\sigma^2_k$ (increasing the number of participants in each study).\n\n## Analytical approach - Power curves\n\nThe most informative approach is plotting the power curves for different values of $\\tau^2$, $\\sigma^2_k$ and $\\theta$ (or $\\mu_{\\theta}$).\n\nYou can use the `power_meta()` function:\n\n```r\npower_meta <- function(es, k, tau2 = 0, n1, n2 = NULL, alpha = 0.05){\n  if(is.null(n2)) n2 <- n1\n  zc <- qnorm(1 - alpha/2)\n  vt <- 1/n1 + 1/n2\n  ves <- (vt + tau2)/k\n  lambda <- es/sqrt(ves)\n  (1 - pnorm(zc - lambda)) + pnorm(-zc - lambda)\n}\n```\n\n## Analytical approach - Power curves\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code  code-fold=\"true\"}\nk <- c(5, 10, 30, 50, 100)\nes <- c(0.1, 0.3)\ntau2 <- c(0, 0.05, 0.1, 0.2)\nn <- c(10, 30, 50, 100, 1000)\n\npower <- expand_grid(es, k, tau2, n1 = n)\npower$power <- power_meta(power$es, power$k, power$tau2, power$n1)\n\npower$es <- factor(power$es, labels = latex2exp::TeX(sprintf(\"$\\\\mu_{\\\\theta} = %s$\", es)))\npower$tau2 <- factor(power$tau2, labels = latex2exp::TeX(sprintf(\"$\\\\tau^2 = %s$\", tau2)))\n\nggplot(power, aes(x = factor(k), y = power, color = factor(n1))) +\n  geom_point() +\n  geom_line(aes(group = factor(n1))) +\n  facet_grid(es~tau2, labeller = label_parsed) +\n  xlab(\"Number of Studies (k)\") +\n  ylab(\"Power\") +\n  labs(\n    color = latex2exp::TeX(\"$n_1 = n_2$\")\n  )\n```\n\n::: {.cell-output-display}\n![](power-analysis_files/figure-revealjs/unnamed-chunk-10-1.svg){fig-align='center' width=960}\n:::\n:::\n\n\n## Analytical approach - Power curves\n\nWith the analytical approach we can (quickly) do interesting stuff. For example, we fix the total $N = n_1 + n_2$ for a series of $k$ and check the power.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code  code-fold=\"true\"}\n# average meta k = 20, n = 30\nkavg <- 20\nnavg <- 30\nN <- kavg * (navg*2)\nes <- 0.3\ntau2 <- c(0, 0.05, 0.1, 0.2)\nk <- seq(10, 100, 10)\nn1 <- n2 <- round((N/k)/ 2)\n\nsim <- data.frame(es, k, n1, n2)\nsim <- expand_grid(sim, tau2 = tau2)\nsim$power <- power_meta(sim$es, sim$k, sim$tau2, sim$n1, sim$n2)\nsim$N <- with(sim, k * (n1 + n2))\n\nggplot(sim, aes(x = k, y = power, color = factor(tau2))) +\n  geom_line() +\n  ggtitle(latex2exp::TeX(\"Total N ($n_1 + n_2$) = 1200\")) +\n  labs(x = \"Number of Studies (k)\",\n       y = \"Power\",\n       color = latex2exp::TeX(\"$\\\\tau^2$\"))\n```\n\n::: {.cell-output-display}\n![](power-analysis_files/figure-revealjs/unnamed-chunk-11-1.svg){fig-align='center' width=960}\n:::\n:::\n\n\nAs long as $\\tau^2 \\neq 0$ we need more studies (even if the total sample size is the same).\n\n## Simulation-based power\n\nWith simulations we can fix or relax the previous assumptions. For example, let's compute the power for an EE model:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nk <- 10\nes <- 0.3\ntau2 <- 0\nn1 <- n2 <- rep(25, k)\nnsim <- 1000 # more is better\npval <- rep(NA, nsim)\n\nfor(i in 1:nsim){\n  dat <- sim_studies(k, es, tau2, n1, n2)\n  fit <- rma(yi, vi, data = dat, method = \"EE\")\n  pval[i] <- fit$pval\n}\n\nmean(pval <= 0.05)\n#> [1] 0.924\n```\n:::\n\n\nThe value is similar to the analytical simulation. But we can improve it e.g. generating heterogeneous sample sizes.\n\n## Simulation-based power curve\n\nBy repeating the previous approach for a series of parameters we can easily draw a power curve:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nk <- c(5, 10, 50, 100)\nes <- 0.1\ntau2 <- c(0, 0.05, 0.1, 0.2)\nnsim <- 1000\n\ngrid <- expand_grid(k, es, tau2)\npower <- rep(NA, nrow(grid))\n\nfor(i in 1:nrow(grid)){\n  pval <- rep(NA, nsim)\n  for(j in 1:nsim){\n    n <- rpois(grid$k[i], 40)\n    dat <- sim_studies(grid$k[i], grid$es[i], grid$tau2[i], n)\n    fit <- rma(yi, vi, data = dat)\n    pval[j] <- fit$pval\n  }\n  power[i] <- mean(pval <= 0.05)\n}\ngrid$power <- power\n```\n:::\n\n\n## Simulation-based power curve\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code  code-fold=\"true\"}\nggplot(grid, aes(x = factor(k), y = power, color = factor(tau2))) +\n  geom_point() +\n  geom_line(aes(group = factor(tau2))) +\n  labs(\n    y = \"Power\",\n    x = \"Number of studies (k)\",\n    color = latex2exp::TeX(\"$\\\\tau^2$\")\n  )\n```\n\n::: {.cell-output-display}\n![](power-analysis_files/figure-revealjs/unnamed-chunk-14-1.svg){fig-align='center' width=960}\n:::\n:::\n\n\n## Power analysis for meta-regression\n\nThe power for a meta-regression can be easily computed by simulating the moderator effect. For example, let's simulate the effect of a binary predictor $x$.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nk <- seq(10, 100, 10)\nb0 <- 0.2 # average of group 1\nb1 <- 0.1 # difference between group 1 and 2\ntau2r <- 0.2 # residual tau2\nnsim <- 1000\npower <- rep(NA, length(k))\n\nfor(i in 1:length(k)){\n  es <- b0 + b1 * rep(0:1, each = k[i]/2)\n  pval <- rep(NA, nsim)\n  for(j in 1:nsim){\n    n <- round(runif(k[i], 10, 100))\n    dat <- sim_studies(k[i], es, tau2r, n)\n    fit <- rma(yi, vi, data = dat)\n    pval[j] <- fit$pval\n  }\n  power[i] <- mean(pval <= 0.05)\n}\n```\n:::\n\n\n## Power analysis for meta-regression\n\nThen we can plot the results:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code  code-fold=\"true\"}\npower <- data.frame(k = k, power = power)\nggplot(power, aes(x = k, y = power)) +\n  geom_line()\n```\n\n::: {.cell-output-display}\n![](power-analysis_files/figure-revealjs/unnamed-chunk-16-1.svg){fig-align='center' width=960}\n:::\n:::\n\n\n# Multilab Studies {.section}\n\n## Multilab studies\n\nMultilab studies can be seen as a meta-analysis that is planned (a *prospective* meta-analysis) compared to standard *retrospective* meta-analysis.\n\nThe statistical approach is (roughly) the same with the difference that we have control both on $k$ (the number of experimental units) and $n$ the sample size within each unit.\n\nIn multilab studies we have also the raw data (i.e., participant-level data) thus we can do more complex multilevel modeling.\n\n## Meta-analysis as multilevel model\n\nAssuming that we have $k$ studies with raw data available there is no need to aggregate, calculate the effect size and variances and then use an EE or RE model.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nk <- 50\nes <- 0.4\ntau2 <- 0.1\nn <- round(runif(k, 10, 100))\ndat <- vector(mode = \"list\", k)\nthetai <- rnorm(k, 0, sqrt(tau2))\n\nfor(i in 1:k){\n  g1 <- rnorm(n[i], 0, 1)\n  g2 <- rnorm(n[i], es + thetai[i], 1)\n  d <- data.frame(id = 1:(n[i]*2), unit = i, y = c(g1, g2), group = rep(c(0, 1), each = n[i]))\n  dat[[i]] <- d\n}\n\ndat <- do.call(rbind, dat)\nht(dat)\n#>      id unit          y group\n#> 1     1    1  0.2893323     0\n#> 2     2    1 -1.1718120     0\n#> 3     3    1 -0.8300565     0\n#> 4     4    1  0.1406313     0\n#> 5     5    1  1.0616239     0\n#> 5473 65   50  0.3235104     1\n#> 5474 66   50  0.4872725     1\n#> 5475 67   50 -0.5355670     1\n#> 5476 68   50  2.4656131     1\n#> 5477 69   50 -0.6286605     1\n#> 5478 70   50  2.4208509     1\n```\n:::\n\n\n## Meta-analysis as multilevel model\n\nThis is a simple **multilevel model** (pupils within classrooms or trials within participants). We can fit the model using `lme4::lmer()`:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code  code-fold=\"false\"}\nlibrary(lme4)\nfit_lme <- lmer(y ~ group + (1|unit), data = dat)\nsummary(fit_lme)\n#> Linear mixed model fit by REML ['lmerMod']\n#> Formula: y ~ group + (1 | unit)\n#>    Data: dat\n#> \n#> REML criterion at convergence: 15712.6\n#> \n#> Scaled residuals: \n#>     Min      1Q  Median      3Q     Max \n#> -3.4455 -0.6876  0.0186  0.6977  3.2117 \n#> \n#> Random effects:\n#>  Groups   Name        Variance Std.Dev.\n#>  unit     (Intercept) 0.04006  0.2002  \n#>  Residual             1.01432  1.0071  \n#> Number of obs: 5478, groups:  unit, 50\n#> \n#> Fixed effects:\n#>              Estimate Std. Error t value\n#> (Intercept) -0.003784   0.034715  -0.109\n#> group        0.417518   0.027215  15.342\n#> \n#> Correlation of Fixed Effects:\n#>       (Intr)\n#> group -0.392\n```\n:::\n\n\n## Meta-analysis as multilevel model\n\nLet's do the same as a meta-analysis. Firstly we compute the effect sizes for each unit:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ndatagg <- dat |> \n  group_by(unit, group) |> \n  summarise(m = mean(y),\n            sd = sd(y),\n            n = n()) |> \n  pivot_wider(names_from = group, values_from = c(m, sd, n), names_sep = \"\")\n\ndatagg <- escalc(\"MD\", m1i = m1, m2i = m0, sd1i = sd1, sd2i = sd0, n1i = n1, n2i = n0, data = datagg)\n```\n:::\n\n\n## Meta-analysis as multilevel model\n\n\n::: {.cell layout-align=\"center\"}\n\n```\n#> \n#>    unit           m0          m1       sd0       sd1 n0 n1      yi     vi \n#> 1     1 -0.182281099  0.67740970 0.9313053 0.8599736 32 32  0.8597 0.0502 \n#> 2     2 -0.080684001  0.09258349 0.8352305 1.0518596 59 59  0.1733 0.0306 \n#> 3     3 -0.194020177  0.04229138 1.0409077 0.9633482 80 80  0.2363 0.0251 \n#> 4     4 -0.122323160  0.61829855 0.9724882 0.8976187 36 36  0.7406 0.0487 \n#> 5     5  0.240849696  0.27411106 0.9550909 0.8178345 36 36  0.0333 0.0439 \n#> 45   45  0.014118034 -0.16639800 1.1398257 0.9029696 81 81 -0.1805 0.0261 \n#> 46   46  0.258466056  0.70023676 0.9593704 1.0152041 31 31  0.4418 0.0629 \n#> 47   47 -0.108808858 -0.06605484 1.0886507 1.0221369 47 47  0.0428 0.0474 \n#> 48   48 -0.101801658  1.06380067 0.9214148 1.0912795 27 27  1.1656 0.0756 \n#> 49   49 -0.004267983  0.06425461 1.0686583 0.9415882 58 58  0.0685 0.0350 \n#> 50   50 -0.108280467  0.36343002 0.9505833 1.2846007 35 35  0.4717 0.0730\n```\n:::\n\n\n## Meta-analysis as multilevel model\n\nThen we can fit the model:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nfit_rma <- rma(yi, vi, data = datagg)\nfit_rma\n#> \n#> Random-Effects Model (k = 50; tau^2 estimator: REML)\n#> \n#> tau^2 (estimated amount of total heterogeneity): 0.1112 (SE = 0.0306)\n#> tau (square root of estimated tau^2 value):      0.3335\n#> I^2 (total heterogeneity / total variability):   75.80%\n#> H^2 (total variability / sampling variability):  4.13\n#> \n#> Test for Heterogeneity:\n#> Q(df = 49) = 207.6604, p-val < .0001\n#> \n#> Model Results:\n#> \n#> estimate      se    zval    pval   ci.lb   ci.ub      \n#>   0.4653  0.0553  8.4168  <.0001  0.3570  0.5737  *** \n#> \n#> ---\n#> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n:::\n\n\n## Meta-analysis as multilevel modeling\n\nActually the results are very similar where the standard deviation of the intercepts of the `lme4` model is $\\approx \\tau$ and the `group` effect is the intercept of the `rma` model.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ndata.frame(\n  b = c(fixef(fit_lme)[2], fit_rma$b),\n  se = c(summary(fit_lme)$coefficients[2, 2], fit_rma$se),\n  tau2 = c(as.numeric(VarCorr(fit_lme)[[1]]), fit_rma$tau2),\n  model = c(\"lme4\", \"metafor\")\n)\n#>               b         se       tau2   model\n#> group 0.4175182 0.02721483 0.04006087    lme4\n#>       0.4653258 0.05528509 0.11120165 metafor\n```\n:::\n\n\nActually the two model are not exactly the same, especially when using only the aggregated data. See https://www.metafor-project.org/doku.php/tips:rma_vs_lm_lme_lmer.\n\n## Meta-analysis as multilevel modeling\n\nTo note, aggregating data and then computing a standard (non-weighted) model (sometimes this is done with trial-level data) is wrong and should be avoided. Using meta-analysis is clear that aggregating without taking into account the cluster (e.g., study or subject) precision is misleading.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ndataggl <- datagg |> \n  select(unit, m0, m1) |>\n  pivot_longer(c(m0, m1), values_to = \"y\", names_to = \"group\")\n\nsummary(lmer(y ~ group + (1|unit), data = dataggl))\n#> Linear mixed model fit by REML ['lmerMod']\n#> Formula: y ~ group + (1 | unit)\n#>    Data: dataggl\n#> \n#> REML criterion at convergence: 47.9\n#> \n#> Scaled residuals: \n#>      Min       1Q   Median       3Q      Max \n#> -2.31836 -0.54276 -0.03706  0.61381  2.36896 \n#> \n#> Random effects:\n#>  Groups   Name        Variance Std.Dev.\n#>  unit     (Intercept) 0.01407  0.1186  \n#>  Residual             0.07520  0.2742  \n#> Number of obs: 100, groups:  unit, 50\n#> \n#> Fixed effects:\n#>             Estimate Std. Error t value\n#> (Intercept) -0.02872    0.04226  -0.680\n#> groupm1      0.48411    0.05485   8.827\n#> \n#> Correlation of Fixed Effects:\n#>         (Intr)\n#> groupm1 -0.649\n```\n:::\n\n\n## Mulitlab sample size vs unit\n\nWhen planning a multilab study there is an important decision between **increasing the sample size within each unit** (more effort for each lab) or **recruiting more units** with less participants per unit (more effort for the organization).\n\nWe could have the situation where the number of units $k$ is fixed and we can only increase the sample size.\n\nWe can also simulate scenarios where some units collect all data while others did not complete the data collection.\n\n## Fixed $k$, increasing $n$\n\nLet's assume that the maximum number of labs is $10$. How many participants are required assuming a certain amount of heterogeneity?\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nes <- 0.2\nk <- 10\nn1 <- n2 <- seq(10, 500, 10)\ntau2 <- c(0.01, 0.05, 0.1, 0.2)\nsim <- expand_grid(k, es, tau2, n1)\nsim$n2 <- sim$n1\nsim$vt <- with(sim, 1/n1 + 1/n2)\nsim$I2 <- round(with(sim, tau2 / (tau2 + vt)) * 100, 3)\nsim$power <- power_meta(sim$es, sim$k, sim$tau2, sim$n1, sim$n2)\n\nht(sim)\n#> # A tibble: 11 Ã— 8\n#>        k    es  tau2    n1    n2      vt    I2 power\n#>    <dbl> <dbl> <dbl> <dbl> <dbl>   <dbl> <dbl> <dbl>\n#>  1    10   0.2  0.01    10    10 0.2      4.76 0.281\n#>  2    10   0.2  0.01    20    20 0.1      9.09 0.479\n#>  3    10   0.2  0.01    30    30 0.0667  13.0  0.627\n#>  4    10   0.2  0.01    40    40 0.05    16.7  0.733\n#>  5    10   0.2  0.01    50    50 0.04    20    0.807\n#>  6    10   0.2  0.2    450   450 0.00444 97.8  0.288\n#>  7    10   0.2  0.2    460   460 0.00435 97.9  0.288\n#>  8    10   0.2  0.2    470   470 0.00426 97.9  0.288\n#>  9    10   0.2  0.2    480   480 0.00417 98.0  0.288\n#> 10    10   0.2  0.2    490   490 0.00408 98    0.288\n#> 11    10   0.2  0.2    500   500 0.004   98.0  0.288\n```\n:::\n\n\n## Fixed $k$, increasing $n$\n\nWith a fixed $k$, we could reach a plateau even increasing $n$. This depends also on $\\mu_{\\theta}$ and $\\tau^2$.\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](power-analysis_files/figure-revealjs/unnamed-chunk-25-1.svg){fig-align='center' width=960}\n:::\n:::\n\n\n## Multilab replication studies\n\nA special type of multilab studies are the replication projects. There are some paper discussing how to view replication studies as meta-analyses and how to plan them.\n\n- @Hedges2021-of\n- @Schauer2022-mj\n- @Schauer2020-tw\n- @Schauer2021-ja\n- @Schauer2023-yn\n- @Hedges2019-ry\n\n## References <button class=\"btn\"><i class=\"fa fa-download\"></i><a href=\"data:text/x-bibtex;base64,@MISC{Borenstein2009-mo,
  title = {Introduction to {Meta-Analysis}},
  author = {Borenstein, Michael and Hedges, Larry V and Higgins, Julian P T and
  Rothstein, Hannah R},
  date = {2009},
  doi = {10.1002/9780470743386},
  url = {http://dx.doi.org/10.1002/9780470743386},
  keywords = {MA Unconscious WM}
}

@ARTICLE{Jackson2017-dv,
  title = {Power analysis for random-effects meta-analysis},
  author = {Jackson, Dan and Turner, Rebecca},
  journaltitle = {Research synthesis methods},
  publisher = {Wiley Online Library},
  volume = {8},
  issue = {3},
  pages = {290-302},
  date = {2017-09},
  doi = {10.1002/jrsm.1240},
  pmc = {PMC5590730},
  pmid = {28378395},
  issn = {1759-2879,1759-2887},
  abstract = {One of the reasons for the popularity of meta-analysis is the
  notion that these analyses will possess more power to detect effects than
  individual studies. This is inevitably the case under a fixed-effect model.
  However, the inclusion of the between-study variance in the random-effects
  model, and the need to estimate this parameter, can have unfortunate
  implications for this power. We develop methods for assessing the power of
  random-effects meta-analyses, and the average power of the individual studies
  that contribute to meta-analyses, so that these powers can be compared. In
  addition to deriving new analytical results and methods, we apply our methods
  to 1991 meta-analyses taken from the Cochrane Database of Systematic Reviews
  to retrospectively calculate their powers. We find that, in practice, 5 or
  more studies are needed to reasonably consistently achieve powers from
  random-effects meta-analyses that are greater than the studies that contribute
  to them. Not only is statistical inference under the random-effects model
  challenging when there are very few studies but also less worthwhile in such
  cases. The assumption that meta-analysis will result in an increase in power
  is challenged by our findings.},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/jrsm.1240},
  keywords = {cochrane; empirical evaluation; power calculations; random-effects
  meta-analysis},
  language = {en}
}

@ARTICLE{Hedges2019-ry,
  title = {Statistical analyses for studying replication: Meta-analytic
  perspectives},
  author = {Hedges, Larry V and Schauer, Jacob M},
  journaltitle = {Psychological methods},
  publisher = {American Psychological Association (APA)},
  volume = {24},
  issue = {5},
  pages = {557-570},
  date = {2019-10},
  doi = {10.1037/met0000189},
  pmid = {30070547},
  issn = {1082-989X,1939-1463},
  abstract = {Formal empirical assessments of replication have recently become
  more prominent in several areas of science, including psychology. These
  assessments have used different statistical approaches to determine if a
  finding has been replicated. The purpose of this article is to provide several
  alternative conceptual frameworks that lead to different statistical analyses
  to test hypotheses about replication. All of these analyses are based on
  statistical methods used in meta-analysis. The differences among the methods
  described involve whether the burden of proof is placed on replication or
  nonreplication, whether replication is exact or allows for a small amount of
  "negligible heterogeneity," and whether the studies observed are assumed to be
  fixed (constituting the entire body of relevant evidence) or are a sample from
  a universe of possibly relevant studies. The statistical power of each of
  these tests is computed and shown to be low in many cases, raising issues of
  the interpretability of tests for replication. (PsycINFO Database Record (c)
  2019 APA, all rights reserved).},
  url = {http://dx.doi.org/10.1037/met0000189},
  file = {Hedges and Schauer 2019 - Statistical analyses for studying replication - Meta-analytic perspectives.pdf},
  keywords = {replication-methods},
  language = {en}
}

@ARTICLE{Valentine2010-aj,
  title = {How Many Studies Do You Need?: A Primer on Statistical Power for
  {Meta-Analysis}},
  author = {Valentine, Jeffrey C and Pigott, Therese D and Rothstein, Hannah R},
  journaltitle = {Journal of educational and behavioral statistics: a quarterly
  publication sponsored by the American Educational Research Association and the
  American Statistical Association},
  publisher = {American Educational Research Association},
  volume = {35},
  issue = {2},
  pages = {215-247},
  date = {2010-04-01},
  doi = {10.3102/1076998609346961},
  issn = {1076-9986},
  abstract = {In this article, the authors outline methods for using fixed and
  random effects power analysis in the context of meta-analysis. Like
  statistical power analysis for primary studies, power analysis for
  meta-analysis can be done either prospectively or retrospectively and requires
  assumptions about parameters that are unknown. The authors provide some
  suggestions for thinking about these parameters, in particular for the random
  effects variance component. The authors also show how the typically
  uninformative retrospective power analysis can be made more informative. The
  authors then discuss the value of confidence intervals, show how they could be
  used in addition to or instead of retrospective power analysis, and also
  demonstrate that confidence intervals can convey information more effectively
  in some situations than power analyses alone. Finally, the authors take up the
  question ?How many studies do you need to do a meta-analysis?? and show that,
  given the need for a conclusion, the answer is ?two studies,? because all
  other synthesis techniques are less transparent and/or are less likely to be
  valid. For systematic reviewers who choose not to conduct a quantitative
  synthesis, the authors provide suggestions for both highlighting the current
  limitations in the research base and for displaying the characteristics and
  results of studies that were found to meet inclusion criteria.},
  url = {https://doi.org/10.3102/1076998609346961},
  note = {doi: 10.3102/1076998609346961},
  keywords = {MA Unconscious WM}
}

\" download=\"refs_to_download.bib\"> Download .bib file</a></button> {.refs}\n\n::: {#refs}\n:::",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}