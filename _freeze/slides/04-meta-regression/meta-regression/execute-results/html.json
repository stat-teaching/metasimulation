{
  "hash": "369fe1ec0ea91eebc292d2f252f47113",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Meta-regression\"\n---\n\n\n\n\n\n\n# Meta-analysis as (weighted) linear regression {.section}\n\n## MA as (weighted) linear regression\n\nBoth the EE and RE model can be seen as standard (weighted) linear regression models. Precisely, there is a difference in fitting a meta-analysis using `lm` or `lme4::lmer()` and `rma` (see [https://www.metafor-project.org/doku.php/tips:rma_vs_lm_lme_lmer](https://www.metafor-project.org/doku.php/tips:rma_vs_lm_lme_lmer)).\n\n. . .\n\nBeyond these differences a general the EE and RE models are intercept-only linear regressions.\n\n$$\n\\boldsymbol{Y} = \\mathbf{X}\\boldsymbol{\\beta} + \\boldsymbol{\\epsilon}\n$$\n\nThe EE model:\n\n$$\ny_i = \\beta_0 + \\epsilon_i \n$$\n\nThe RE model:\n\n$$\ny_i = \\beta_0 + \\beta_{0_i} + \\epsilon_i \n$$\n\n## MA as (weighted) linear regression\n\nIn the EE model $\\beta_0$ is $\\theta$ and $\\epsilon_i \\sim \\mathcal{N}(0, \\sigma^2_i)$\n\n$$\ny_i = \\beta_0 + \\epsilon_i \n$$\n\nIn the RE model $\\beta_0$ is $\\mu_{\\theta}$ and $\\beta_{0_i}$ are the $\\delta_i$.\n\n## Explaining $\\tau^2$\n\nSo far we simply assumed $\\tau^2 = 0$ (for the EE model) or estimated it using the RE model.\n\n. . .\n\nWe can extend the intercept-only meta-analysis by including study-level predictors (as in standard linear regression) to explain the estimated true heterogeneity.\n\n## Explaining $\\tau^2$\n\nLet's make an example where we simulate a meta-analysis with $k = 100$ studies. Beyond the effect size, we extracted an experimental condition where 50 studies where lab-based experiments $x_{lab}$ and 50 studies where online experiments.\n\nWe assume that there could be a **lab effect** thus we included a predictor in the model.\n\n\n::: {.cell layout-align=\"center\"}\n\n:::\n\n\n## Explaining $\\tau^2$\n\nNow the model have a predictor $x$ (the type of experiment) and two parameters $\\beta_0$ and $\\beta_1$. Depending on the contrast coding (default to `contr.treatment()` in R) the $\\beta_0$ is different. Coding `exp` as 0 for lab-based experiments and 1 for online experiments:\n\n$$\ny_i = \\beta_0 + \\beta_1X_{1_i} + \\epsilon_i\n$$\n\n$$\ny_{\\text{lab}_i} = \\beta_0 + \\epsilon_i\n$$\n\n$$\ny_{\\text{online}_i} = \\beta_0 + \\beta_1 + \\epsilon_i\n$$\n\n## Explaining $\\tau^2$\n\nWhat is missing is the random-effect. Basically we still have $\\tau^2$ determining the $\\delta_i \\sim \\mathcal{N}(0, \\tau^2)$ but now is the residual $\\tau^2_r$. The heterogeneity after including the predictor.\n\n$$\ny_i = \\beta_0 + \\beta_{0_i} + \\beta_1X_{1_i} + \\epsilon_i\n$$ {#eq-metareg-cat}\n\n$$\n\\beta_{0_i} \\sim \\mathcal{N}(0, \\tau^2_r)\n$$\n\nClearly the difference between $\\tau^2$ (the total heterogeneity) and $\\tau^2_r$ (residual heterogeneity) is an index of the impact of $X$.\n\n## Simulating the $X$ effect\n\nTo simulate a meta-regression we just need to choose the parameters values ($\\beta_0$ and $\\beta_1$) and implement @eq-metareg-cat. Using treatment coding, $\\beta_0$ is the effect size when $X = 0$ (i.e., lab-based experiments) and $\\beta_1$ is the difference between lab and online experiments.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nb0 <- 0.3 # lab-based effect size\nb1 <- 0.5 # online - lab-based --> online = b0 + b1\nexp_dummy <- ifelse(exp == \"lab\", 0, 1) # dummy version\nes <- b0 + b1 * exp_dummy\nht(data.frame(exp, exp_dummy, es))\n#>        exp exp_dummy  es\n#> 1      lab         0 0.3\n#> 2      lab         0 0.3\n#> 3      lab         0 0.3\n#> 4      lab         0 0.3\n#> 5      lab         0 0.3\n#> 95  online         1 0.8\n#> 96  online         1 0.8\n#> 97  online         1 0.8\n#> 98  online         1 0.8\n#> 99  online         1 0.8\n#> 100 online         1 0.8\n```\n:::\n\n\n## Simulating the $X$ effects\n\nNow we can use the `sim_studies()` function as usual. The difference is that `es` is no longer a single value but a vector (with different values according to the $X$ level) and `tau2` is $\\tau^2_r$ (this the leftover heterogeneity after including the $X$ effect)\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ntau2r <- 0.05 # residual heterogeneity\ndat <- sim_studies(k = k, es = es, tau2 = tau2r, n1 = n, add = list(exp = exp))\nht(dat)\n#> \n#>      id      yi     vi n1 n2    exp \n#> 1     1 -0.1088 0.0462 40 40    lab \n#> 2     2  0.4318 0.0438 42 42    lab \n#> 3     3 -0.0455 0.0365 41 41    lab \n#> 4     4  0.6198 0.0495 26 26    lab \n#> 5     5  0.8817 0.0406 45 45    lab \n#> 95   95  0.2727 0.0539 38 38 online \n#> 96   96  0.6494 0.0611 36 36 online \n#> 97   97  0.6794 0.0534 33 33 online \n#> 98   98  0.4407 0.0380 45 45 online \n#> 99   99  0.4536 0.0469 37 37 online \n#> 100 100  0.3602 0.0705 27 27 online\n```\n:::\n\n\n## Fitting a meta-regression Model\n\nTo fit a meta-regression we still use the `metafor::rma()` function, adding the `mods = ~` parameter with the model formula (same as the right-hand side of a `y ~ x` call in `lm`). The name of the predictor in the formula need to match a column of the `data = ` dataframe.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nfit <- rma(yi, vi, mods = ~ exp, data = dat, method = \"REML\")\nsummary(fit)\n#> \n#> Mixed-Effects Model (k = 100; tau^2 estimator: REML)\n#> \n#>   logLik  deviance       AIC       BIC      AICc   \n#> -21.8286   43.6573   49.6573   57.4122   49.9126   \n#> \n#> tau^2 (estimated amount of residual heterogeneity):     0.0408 (SE = 0.0129)\n#> tau (square root of estimated tau^2 value):             0.2021\n#> I^2 (residual heterogeneity / unaccounted variability): 45.43%\n#> H^2 (unaccounted variability / sampling variability):   1.83\n#> R^2 (amount of heterogeneity accounted for):            38.44%\n#> \n#> Test for Residual Heterogeneity:\n#> QE(df = 98) = 179.6024, p-val < .0001\n#> \n#> Test of Moderators (coefficient 2):\n#> QM(df = 1) = 29.2725, p-val < .0001\n#> \n#> Model Results:\n#> \n#>            estimate      se    zval    pval   ci.lb   ci.ub      \n#> intrcpt      0.3975  0.0424  9.3674  <.0001  0.3143  0.4806  *** \n#> exponline    0.3261  0.0603  5.4104  <.0001  0.2080  0.4443  *** \n#> \n#> ---\n#> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n:::\n\n\n## Intepreting a meta-regression Model\n\nThe output is similar to the RE model with few additions:\n\n- Everything related to the heterogeneity ($H^2$, $I^2$, $Q$, etc.) is now about **residual heterogeneity**\n- There is the (pseudo) $R^2$\n- There is an overall test for the moderators $Q_M$\n- There is a section (similar to standard regression models) with the estimated parameters, standard error and Wald test\n\n## Model parameters\n\n`intrcpt` and `exponline` are the estimates of $\\beta_0$ and $\\beta_1$. The interpretation depends on the scale of the effect size and the contrast coding.\n\nWe can plot the model results using the `metafor::regplot()`^[The functions is made for numerical variables thus is less appropriate for categorical variables].\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nregplot(fit)\n```\n\n::: {.cell-output-display}\n![](meta-regression_files/figure-revealjs/unnamed-chunk-7-1.svg){fig-align='center' width=960}\n:::\n:::\n\n\n## Omnibus Moderator Test\n\nThe `Test of Moderators` section report the so-called omnibus test for model coeffiecients. Is a simultaneous test for 1 or more coefficients where $H_0: \\beta_j = 0$.\n\nIn this case, **coefficient 2** means that we are testing only the 2nd coefficient $\\beta_1$. By default, the intercept is ignored. In fact, the `exponline` line and the omnibus test are the same (the $\\chi^2$ is just the $z^2$)\n\n\n::: {.cell layout-align=\"center\"}\n\n```\n#> Test of Moderators (coefficient 2):\n#> QM(df = 1) = 29.2725, p-val < .0001\n#>            estimate      se    zval    pval   ci.lb   ci.ub      \n#> intrcpt      0.3975  0.0424  9.3674  <.0001  0.3143  0.4806  *** \n#> exponline    0.3261  0.0603  5.4104  <.0001  0.2080  0.4443  ***\n```\n:::\n\n\n## General Linear Hypotheses Testing (GLHT)\n\nWe can also test any combination of parameters. For example we could test if lab-based experiments and online experiments are both different from 0. This is the same as fitting a model without the intercept^[see [https://www.metafor-project.org/doku.php/tips:models_with_or_without_intercept](https://www.metafor-project.org/doku.php/tips:models_with_or_without_intercept) on removing the intercept] thus estimating the cell means [see @Schad2020-ht].\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# now we are testing two coefficients\nfit_no_int <- rma(yi, vi, mods = ~ 0 + exp, data = dat)\n```\n:::\n\n\n## General Linear Hypotheses Testing (GLHT)\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nfit_no_int\n#> \n#> Mixed-Effects Model (k = 100; tau^2 estimator: REML)\n#> \n#> tau^2 (estimated amount of residual heterogeneity):     0.0408 (SE = 0.0129)\n#> tau (square root of estimated tau^2 value):             0.2021\n#> I^2 (residual heterogeneity / unaccounted variability): 45.43%\n#> H^2 (unaccounted variability / sampling variability):   1.83\n#> \n#> Test for Residual Heterogeneity:\n#> QE(df = 98) = 179.6024, p-val < .0001\n#> \n#> Test of Moderators (coefficients 1:2):\n#> QM(df = 2) = 373.4033, p-val < .0001\n#> \n#> Model Results:\n#> \n#>            estimate      se     zval    pval   ci.lb   ci.ub      \n#> explab       0.3975  0.0424   9.3674  <.0001  0.3143  0.4806  *** \n#> exponline    0.7236  0.0428  16.9013  <.0001  0.6397  0.8075  *** \n#> \n#> ---\n#> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n:::\n\n\n## General Linear Hypotheses Testing (GLHT)\n\nA more elegant way is by using the GLHT framework. Basically we provide a contrast matrix expressing linear combinations of model parameters to be tested. In our case $\\text{lab} = \\beta_0 = 0$ and $\\text{online} = \\beta_0 + \\beta_1 = 0$.\n\nPractically, the matrix formulation is the following:\n\n$$\n\\begin{pmatrix}  \n1 & 0 \\\\\n1 & 1\n\\end{pmatrix}\n\\begin{pmatrix}  \n\\beta_0\\\\\n\\beta_1\n\\end{pmatrix}\n=\n\\begin{pmatrix}  \n0\\\\\n0\n\\end{pmatrix}\n$$\n\nIn R:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nC <- rbind(c(1, 0), c(1, 1))\nB <- coef(fit)\nC %*% B # same as coef(fit)[1] and coef(fit)[1] +  coef(fit)[2]\n#>           [,1]\n#> [1,] 0.3974823\n#> [2,] 0.7236168\n```\n:::\n\n\n## General Linear Hypotheses Testing (GLHT)\n\nWe can use the `anova()` function providing the model and the hypothesis matrix.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nanova(fit) # the default\n#> \n#> Test of Moderators (coefficient 2):\n#> QM(df = 1) = 29.2725, p-val < .0001\nanova(fit, X = C)\n#> \n#> Hypotheses:                           \n#> 1:             intrcpt = 0 \n#> 2: intrcpt + exponline = 0 \n#> \n#> Results:\n#>    estimate     se    zval   pval \n#> 1:   0.3975 0.0424  9.3674 <.0001 \n#> 2:   0.7236 0.0428 16.9013 <.0001 \n#> \n#> Omnibus Test of Hypotheses:\n#> QM(df = 2) = 373.4033, p-val < .0001\n```\n:::\n\n\nNotice that is the same as the model without the intercept.\n\n## Likelihood Ratio Test (LRT)\n\nAs in standard regression modelling, we can also compare models using LRT. The `anova()` function will compute the LRT when two (nested) models are provided. In this case we compared a null (intercept-only) model with the model including the predictor.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# the null model\nfit0 <- rma(yi, vi, data = dat, method = \"REML\")\nanova(fit0, fit, refit = TRUE) # refit = TRUE because LRT with REML is not meaningful, using ML instead\n#> \n#>         df     AIC     BIC    AICc   logLik     LRT   pval       QE  tau^2 \n#> Full     3 48.5151 56.3306 48.7651 -21.2575                179.6024 0.0390 \n#> Reduced  2 72.7633 77.9737 72.8870 -34.3817 26.2482 <.0001 232.4328 0.0652 \n#>              R^2 \n#> Full             \n#> Reduced 40.1114%\n```\n:::\n\n\n## $R^2$\n\nThe $R^2$ value reported in the model output is not calculated as in standard regression analysis.\n\n$$\nR^2 = 1 - \\frac{\\tau^2_r}{\\tau^2}\n$$\n\nBasically is the percentage of heterogeneity reduction from the intercept-only model to the model including predictors.\n\nIn R:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n(1 - fit$tau2/fit0$tau2)*100\n#> [1] 38.43963\nfit$R2\n#> [1] 38.43963\n```\n:::\n\n\n## $R^2$\n\nDespite useful, the $R^2$ has some limitations:\n\n- @Lopez-Lopez2014-it showed that precise estimations require a large number of studies $k$ \n- Sometimes could results in negative values (usually truncated to zero)\n- Depends on the $\\tau^2$ estimator\n\nMore about $R^2$ and limitations can be found:\n\n- [https://www.metafor-project.org/doku.php/faq#for_mixed-effects_models_how_i](https://www.metafor-project.org/doku.php/faq#for_mixed-effects_models_how_i)\n- [https://www.metafor-project.org/doku.php/tips:ci_for_r2](https://www.metafor-project.org/doku.php/tips:ci_for_r2)\n\n## Numerical predictor\n\nThe same logic of simulating a meta-regression can be applied to numerical predictors. We still have $\\beta_0$ and $\\beta_1$ but $X$ has more levels. Let's simulate an impact of the average participants' age on the effect size.\n\n- $\\beta_0$ is the effect size when **age** is zero\n- $\\beta_1$ is the expected increase in the effect size for a unit increase in `age`\n\nHow we can choose plausible values for the parameters and parametrize the model correctly?\n\n## Parametrize $\\beta_0$\n\nThe intepretation (and the inference) of $\\beta_0$ is strongly dependent on the type of numerical predictor. An age of zero is (probably) empirically meaningless thus the  $\\beta_0$ is somehow not useful.\n\nWe can for example mean-center (or other type of centering procedure) moving the zero on a meaningful value.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nage <- 10:50 # the raw vector\nage0 <- age - mean(age) # centering on the mean\nage20 <- age - min(age) # centering on the minimum\n\nht(data.frame(age, age0, age20))\n#>    age age0 age20\n#> 1   10  -20     0\n#> 2   11  -19     1\n#> 3   12  -18     2\n#> 4   13  -17     3\n#> 5   14  -16     4\n#> 36  45   15    35\n#> 37  46   16    36\n#> 38  47   17    37\n#> 39  48   18    38\n#> 40  49   19    39\n#> 41  50   20    40\n```\n:::\n\n\n## Parametrize $\\beta_0$\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](meta-regression_files/figure-revealjs/unnamed-chunk-16-1.svg){fig-align='center' width=960}\n:::\n:::\n\n\n## Parametrize $\\beta_0$\n\nUsing different parametrizations will only affect the estimation (and the interpretation) of $\\beta_0$. Other parameters and indexes will be the same.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nk <- 100\nb0 <- 0.2 # effect size when age 0\nb1 <- 0.05 # slope (random for now)\nage <- round(runif(k, 20, 50)) # sampling from uniform distribution\ntau2r <- 0.05\nn <- 10 + rpois(k, 30 - 10)\n\nes <- b0 + b1 * age # raw\n\nage0 <- age - mean(age)\nage20 <- age - 20\n\ndat <- sim_studies(k = k, es = es, tau2 = tau2r, n1 = n, add = list(age = age, age0 = age0, age20 = age20))\n\nfit <- rma(yi, vi, mods = ~ age, data = dat)\nfit0 <- rma(yi, vi, mods = ~ age0, data = dat)\nfit20 <- rma(yi, vi, mods = ~ age20, data = dat)\n\n# showing the intercept\ncompare_rma(fit, fit0, fit20, extra_params = \"R2\") |> \n  round(3)\n#> fit: rma(yi = yi, vi = vi, mods = ~age, data = dat)\n#> fit0: rma(yi = yi, vi = vi, mods = ~age0, data = dat)\n#> fit20: rma(yi = yi, vi = vi, mods = ~age20, data = dat)\n#>                fit   fit0  fit20\n#> b (intrcpt)  0.277  1.981  1.255\n#> se           0.140  0.033  0.067\n#> zval         1.988 59.335 18.784\n#> pval         0.047  0.000  0.000\n#> ci.lb        0.004  1.916  1.124\n#> ci.ub        0.551  2.047  1.386\n#> R2          78.951 78.951 78.951\n#> I2          42.044 42.044 42.044\n#> tau2         0.046  0.046  0.046\n\n  # showing the intercept\ncompare_rma(fit, fit0, fit20, b = \"age\", extra_params = \"R2\") |> \n  round(3)\n#> fit: rma(yi = yi, vi = vi, mods = ~age, data = dat)\n#> fit0: rma(yi = yi, vi = vi, mods = ~age0, data = dat)\n#> fit20: rma(yi = yi, vi = vi, mods = ~age20, data = dat)\n#>            fit   fit0  fit20\n#> b (age)  0.049  0.049  0.049\n#> se       0.004  0.004  0.004\n#> zval    12.604 12.604 12.604\n#> pval     0.000  0.000  0.000\n#> ci.lb    0.041  0.041  0.041\n#> ci.ub    0.056  0.056  0.056\n#> R2      78.951 78.951 78.951\n#> I2      42.044 42.044 42.044\n#> tau2     0.046  0.046  0.046\n```\n:::\n\n\n## Choosing $\\beta_1$\n\nThe core of the model is $\\beta_1$ that is the **age** effect. Compared to the categorical case where $\\beta_1$ is just the standardized difference between two conditions, with numerical $X$ choosing a meaningful $\\beta_1$ is more challenging.\n\nTwo (maybe more) strategies:\n\n- simulating a lot of effects sizes fixing $beta_0$ and $\\beta_1$ and see the expected range of $y_i$\n- fixing a certain $R^2$ and choose the $\\beta_1$ producing that $R^2$\n- ...\n\n## $\\beta_1$ by simulations\n\nA strategy could be to simulate from the generative model a large number of studies and see the expected range of effect size [@Gelman2020-tg, Chapter 5 and p. 97]. A large number of unplausible values suggest that the chosen $\\beta_1$ is probably not appropriate.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nk <- 1e3\nn <- 30\ntau2 <- 0\nx <- runif(k, 20, 50) # age\nb0 <- 0.1\nb1 <- c(0.001, 0.05, 0.2)\nesl <- lapply(b1, function(b) b0 + b*x)\ndatl <- lapply(esl, function(es) sim_studies(k = k, es = es, tau2 = tau2, n1 = n, add = list(x = x)))\nnames(datl) <- b1\ndat <- dplyr::bind_rows(datl, .id = \"b1\")\nht(dat)\n#> \n#>         b1   id      yi     vi n1 n2        x \n#> 1    0.001    1  0.0298 0.0631 30 30 41.04808 \n#> 2    0.001    2  0.2132 0.0508 30 30 42.46508 \n#> 3    0.001    3 -0.0071 0.0631 30 30 38.81188 \n#> 4    0.001    4 -0.0116 0.1049 30 30 30.88555 \n#> 5    0.001    5 -0.0313 0.0568 30 30 22.62966 \n#> 2995   0.2  995 10.0363 0.0625 30 30 47.41694 \n#> 2996   0.2  996  6.9607 0.0720 30 30 35.56750 \n#> 2997   0.2  997  6.8963 0.0517 30 30 33.82691 \n#> 2998   0.2  998  4.8710 0.0503 30 30 25.03220 \n#> 2999   0.2  999  4.5953 0.0649 30 30 22.85928 \n#> 3000   0.2 1000  8.8629 0.0694 30 30 45.29689\n```\n:::\n\n\n## $\\beta_1$ by simulations\n\nClearly given the limited range of the $x$ variable (`age`) some $\\beta_1$ values are implausible leading to effect sizes that are out of a meaningful empirical range.\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](meta-regression_files/figure-revealjs/unnamed-chunk-19-1.svg){fig-align='center' width=960}\n:::\n:::\n\n\n## Fixing $R^2$\n\nWe can use the approach by @Lopez-Lopez2014-it where predictors $x$ are sampled from a standard normal distribution (or standardized). $\\beta_1$ is calculated as $\\beta_1 = \\sqrt{\\tau^2 R^2}$ and the residual heterogeneity as $\\tau^2_r = \\tau^2 - \\beta^2_1$.\n\n\n::: {.cell layout-align=\"center\"}\n\n:::\n\n\n## Fixing $R^2$\n\nWe can check the simulation approach:\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nk <- 1e3\n1 - tau2r/tau2\n#> [1] 0.4\nx <- rnorm(k)\nes <- b0 + b1 * x\ndat <- sim_studies(k, es, tau2r, n1 = 1e3, add = list(x = x))\nfit <- rma(yi, vi, data = dat, mods = ~x)\nsummary(fit)\n#> \n#> Mixed-Effects Model (k = 1000; tau^2 estimator: REML)\n#> \n#>    logLik   deviance        AIC        BIC       AICc   \n#> -530.7334  1061.4667  1067.4667  1082.1840  1067.4909   \n#> \n#> tau^2 (estimated amount of residual heterogeneity):     0.1676 (SE = 0.0076)\n#> tau (square root of estimated tau^2 value):             0.4094\n#> I^2 (residual heterogeneity / unaccounted variability): 98.82%\n#> H^2 (unaccounted variability / sampling variability):   85.06\n#> R^2 (amount of heterogeneity accounted for):            39.90%\n#> \n#> Test for Residual Heterogeneity:\n#> QE(df = 998) = 84936.6718, p-val < .0001\n#> \n#> Test of Moderators (coefficient 2):\n#> QM(df = 1) = 656.5223, p-val < .0001\n#> \n#> Model Results:\n#> \n#>          estimate      se     zval    pval   ci.lb   ci.ub      \n#> intrcpt    0.1007  0.0130   7.7308  <.0001  0.0752  0.1262  *** \n#> x          0.3275  0.0128  25.6227  <.0001  0.3024  0.3525  *** \n#> \n#> ---\n#> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n:::\n\n\n## $R^2$ using simulations\n\nThe results from @Lopez-Lopez2014-it (and also our previous simulation) suggested that we need a large number of studies for precise $R^2$ estimations. Let's check using simulations the sampling distribution of $R^2$ using a plausible meta-analysis scenario.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nk <- 40 # number of studies\nn <- 10 + rpois(k, 40 - 10) # sample size\ntau2 <- 0.05 # tau ~ 0.22\nR2 <- 0.3\nb0 <- 0.1\nb1_2 <- tau2 * R2\nb1 <- sqrt(b1_2)\ntau2r <- tau2 - b1_2\nnsim <- 1e3\n\nR2i <- rep(NA, nsim)\n\nfor(i in 1:nsim){\n  x <- rnorm(k)\n  dat <- sim_studies(k = k, es = b0 + b1*x, tau2 = tau2r, n1 = n, add = list(x))\n  fit <- rma(yi, vi, data = dat, mods = ~x)\n  R2i[i] <- fit$R2\n}\n```\n:::\n\n\n## $R^2$ using simulations\n\nWe estimated the true $R^2$ correctly but there is a lot of uncertainty with a plausible meta-analysis scenario. There are a lot of meta-analysis also with lower $k$ worsening the results.\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](meta-regression_files/figure-revealjs/unnamed-chunk-23-1.svg){fig-align='center' width=960}\n:::\n:::\n\n\n## References <button class=\"btn\"><i class=\"fa fa-download\"></i><a href=\"data:text/x-bibtex;base64,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\" download=\"refs_to_download.bib\"> Download .bib file</a></button> {.refs}\n\n::: {#refs}\n:::",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}