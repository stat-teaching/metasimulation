{
  "hash": "3d50b2de81868724c29f016a6e93eb47",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Meta-regression\"\n---\n\n\n\n\n\n\n# Meta-analysis as (weighted) linear regression {.section}\n\n## MA as (weighted) linear regression\n\nBoth the EE and RE model can be seen as standard (weighted) linear regression models. Precisely, there is a difference in fitting a meta-analysis using `lm` or `lme4::lmer()` and `rma` (see [https://www.metafor-project.org/doku.php/tips:rma_vs_lm_lme_lmer](https://www.metafor-project.org/doku.php/tips:rma_vs_lm_lme_lmer)).\n\n. . .\n\nBeyond these differences a general the EE and RE models are intercept-only linear regressions.\n\n$$\n\\boldsymbol{Y} = \\mathbf{X}\\boldsymbol{\\beta} + \\boldsymbol{\\epsilon}\n$$\n\nThe EE model:\n\n$$\ny_i = \\beta_0 + \\epsilon_i \n$$\n\nThe RE model:\n\n$$\ny_i = \\beta_0 + \\beta_{0_i} + \\epsilon_i \n$$\n\n## MA as (weighted) linear regression\n\nIn the EE model $\\beta_0$ is $\\theta$ and $\\epsilon_i \\sim \\mathcal{N}(0, \\sigma^2_i)$\n\n$$\ny_i = \\beta_0 + \\epsilon_i \n$$\n\nIn the RE model $\\beta_0$ is $\\mu_{\\theta}$ and $\\beta_{0_i}$ are the $\\delta_i$.\n\n## Explaining $\\tau^2$\n\nSo far we simply assumed $\\tau^2 = 0$ (for the EE model) or estimated it using the RE model.\n\n. . .\n\nWe can extend the intercept-only meta-analysis by including study-level predictors (as in standard linear regression) to explain the estimated true heterogeneity.\n\n## Explaining $\\tau^2$\n\nLet's make an example where we simulate a meta-analysis with $k = 100$ studies. Beyond the effect size, we extracted an experimental condition where 50 studies where lab-based experiments $x_{lab}$ and 50 studies where online experiments.\n\nWe assume that there could be a **lab effect** thus we included a predictor in the model.\n\n\n::: {.cell layout-align=\"center\"}\n\n:::\n\n\n## Explaining $\\tau^2$\n\nNow the model have a predictor $x$ (the type of experiment) and two parameters $\\beta_0$ and $\\beta_1$. Depending on the contrast coding (default to `contr.treatment()` in R) the $\\beta_0$ is different. Coding `exp` as 0 for lab-based experiments and 1 for online experiments:\n\n$$\ny_i = \\beta_0 + \\beta_1X_{1_i} + \\epsilon_i\n$$\n\n$$\ny_{\\text{lab}_i} = \\beta_0 + \\epsilon_i\n$$\n\n$$\ny_{\\text{online}_i} = \\beta_0 + \\beta_1 + \\epsilon_i\n$$\n\n## Explaining $\\tau^2$\n\nWhat is missing is the random-effect. Basically we still have $\\tau^2$ determining the $\\delta_i \\sim \\mathcal{N}(0, \\tau^2)$ but now is the residual $\\tau^2_r$. The heterogeneity after including the predictor.\n\n$$\ny_i = \\beta_0 + \\beta_{0_i} + \\beta_1X_{1_i} + \\epsilon_i\n$$ {#eq-metareg-cat}\n\n$$\n\\beta_{0_i} \\sim \\mathcal{N}(0, \\tau^2_r)\n$$\n\nClearly the difference between $\\tau^2$ (the total heterogeneity) and $\\tau^2_r$ (residual heterogeneity) is an index of the impact of $X$.\n\n## Simulating the $X$ effect\n\nTo simulate a meta-regression we just need to choose the parameters values ($\\beta_0$ and $\\beta_1$) and implement @eq-metareg-cat. Using treatment coding, $\\beta_0$ is the effect size when $X = 0$ (i.e., lab-based experiments) and $\\beta_1$ is the difference between lab and online experiments.\n\n\n::: {.cell layout-align=\"center\"}\n\n```\n#>        exp exp_dummy  es\n#> 1      lab         0 0.3\n#> 2      lab         0 0.3\n#> 3      lab         0 0.3\n#> 4      lab         0 0.3\n#> 5      lab         0 0.3\n#> 95  online         1 0.8\n#> 96  online         1 0.8\n#> 97  online         1 0.8\n#> 98  online         1 0.8\n#> 99  online         1 0.8\n#> 100 online         1 0.8\n```\n:::\n\n\n## Simulating the $X$ effects\n\nNow we can use the `sim_studies()` function as usual. The difference is that `es` is no longer a single value but a vector (with different values according to the $X$ level) and `tau2` is $\\tau^2_r$ (this the leftover heterogeneity after including the $X$ effect)\n\n\n::: {.cell layout-align=\"center\"}\n\n```\n#> \n#>      id      yi     vi n1 n2    exp \n#> 1     1  0.1114 0.0505 40 40    lab \n#> 2     2 -0.1330 0.0624 35 35    lab \n#> 3     3  0.3525 0.0632 37 37    lab \n#> 4     4  0.3906 0.0428 51 51    lab \n#> 5     5  0.3876 0.0504 42 42    lab \n#> 95   95  0.5008 0.0495 39 39 online \n#> 96   96  0.5525 0.0550 34 34 online \n#> 97   97  0.8551 0.0402 42 42 online \n#> 98   98  0.8025 0.0546 34 34 online \n#> 99   99  1.1299 0.0512 37 37 online \n#> 100 100  1.1799 0.0672 33 33 online\n```\n:::\n\n\n## Fitting a meta-regression Model\n\nTo fit a meta-regression we still use the `metafor::rma()` function, adding the `mods = ~` parameter with the model formula (same as the right-hand side of a `y ~ x` call in `lm`). The name of the predictor in the formula need to match a column of the `data = ` dataframe.\n\n\n::: {.cell layout-align=\"center\"}\n\n```\n#> \n#> Mixed-Effects Model (k = 100; tau^2 estimator: REML)\n#> \n#>   logLik  deviance       AIC       BIC      AICc   \n#> -24.0549   48.1098   54.1098   61.8647   54.3652   \n#> \n#> tau^2 (estimated amount of residual heterogeneity):     0.0465 (SE = 0.0138)\n#> tau (square root of estimated tau^2 value):             0.2157\n#> I^2 (residual heterogeneity / unaccounted variability): 48.28%\n#> H^2 (unaccounted variability / sampling variability):   1.93\n#> R^2 (amount of heterogeneity accounted for):            58.02%\n#> \n#> Test for Residual Heterogeneity:\n#> QE(df = 98) = 189.6112, p-val < .0001\n#> \n#> Test of Moderators (coefficient 2):\n#> QM(df = 1) = 68.6500, p-val < .0001\n#> \n#> Model Results:\n#> \n#>            estimate      se    zval    pval   ci.lb   ci.ub      \n#> intrcpt      0.2408  0.0440  5.4704  <.0001  0.1545  0.3271  *** \n#> exponline    0.5170  0.0624  8.2855  <.0001  0.3947  0.6393  *** \n#> \n#> ---\n#> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n:::\n\n\n## Intepreting a meta-regression Model\n\nThe output is similar to the RE model with few additions:\n\n- Everything related to the heterogeneity ($H^2$, $I^2$, $Q$, etc.) is now about **residual heterogeneity**\n- There is the (pseudo) $R^2$\n- There is an overall test for the moderators $Q_M$\n- There is a section (similar to standard regression models) with the estimated parameters, standard error and Wald test\n\n## Model parameters\n\n`intrcpt` and `exponline` are the estimates of $\\beta_0$ and $\\beta_1$. The interpretation depends on the scale of the effect size and the contrast coding.\n\nWe can plot the model results using the `metafor::regplot()`^[The functions is made for numerical variables thus is less appropriate for categorical variables].\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](meta-regression_files/figure-revealjs/unnamed-chunk-7-1.svg){fig-align='center' width=960}\n:::\n:::\n\n\n## Omnibus Moderator Test\n\nThe `Test of Moderators` section report the so-called omnibus test for model coeffiecients. Is a simultaneous test for 1 or more coefficients where $H_0: \\beta_j = 0$.\n\nIn this case, **coefficient 2** means that we are testing only the 2nd coefficient $\\beta_1$. By default, the intercept is ignored. In fact, the `exponline` line and the omnibus test are the same (the $\\chi^2$ is just the $z^2$)\n\n\n::: {.cell layout-align=\"center\"}\n\n```\n#> Test of Moderators (coefficient 2):\n#> QM(df = 1) = 68.6500, p-val < .0001\n#>            estimate      se    zval    pval   ci.lb   ci.ub      \n#> intrcpt      0.2408  0.0440  5.4704  <.0001  0.1545  0.3271  *** \n#> exponline    0.5170  0.0624  8.2855  <.0001  0.3947  0.6393  ***\n```\n:::\n\n\n## General Linear Hypotheses Testing (GLHT)\n\nWe can also test any combination of parameters. For example we could test if lab-based experiments and online experiments are both different from 0. This is the same as fitting a model without the intercept^[see [https://www.metafor-project.org/doku.php/tips:models_with_or_without_intercept](https://www.metafor-project.org/doku.php/tips:models_with_or_without_intercept) on removing the intercept] thus estimating the cell means [see @Schad2020-ht].\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# now we are testing two coefficients\nfit_no_int <- rma(yi, vi, mods = ~ 0 + exp, data = dat)\nfit_no_int\n#> \n#> Mixed-Effects Model (k = 100; tau^2 estimator: REML)\n#> \n#> tau^2 (estimated amount of residual heterogeneity):     0.0465 (SE = 0.0138)\n#> tau (square root of estimated tau^2 value):             0.2157\n#> I^2 (residual heterogeneity / unaccounted variability): 48.28%\n#> H^2 (unaccounted variability / sampling variability):   1.93\n#> \n#> Test for Residual Heterogeneity:\n#> QE(df = 98) = 189.6112, p-val < .0001\n#> \n#> Test of Moderators (coefficients 1:2):\n#> QM(df = 2) = 323.5856, p-val < .0001\n#> \n#> Model Results:\n#> \n#>            estimate      se     zval    pval   ci.lb   ci.ub      \n#> explab       0.2408  0.0440   5.4704  <.0001  0.1545  0.3271  *** \n#> exponline    0.7578  0.0442  17.1365  <.0001  0.6711  0.8444  *** \n#> \n#> ---\n#> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n:::\n\n\n## General Linear Hypotheses Testing (GLHT)\n\nA more elegant way is by using the GLHT framework. Basically we provide a contrast matrix expressing linear combinations of model parameters to be tested. In our case $\\text{lab} = \\beta_0 = 0$ and $\\text{online} = \\beta_0 + \\beta_1 = 0$.\n\nPractically, the matrix formulation is the following:\n\n$$\n\\begin{pmatrix}  \n1 & 0 \\\\\n1 & 1\n\\end{pmatrix}\n\\begin{pmatrix}  \n\\beta_0\\\\\n\\beta_1\n\\end{pmatrix}\n=\n\\begin{pmatrix}  \n0\\\\\n0\n\\end{pmatrix}\n$$\n\nIn R:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nC <- rbind(c(1, 0), c(1, 1))\nB <- coef(fit)\nC %*% B # same as coef(fit)[1] and coef(fit)[1] +  coef(fit)[2]\n#>           [,1]\n#> [1,] 0.2407981\n#> [2,] 0.7577632\n```\n:::\n\n\n## General Linear Hypotheses Testing (GLHT)\n\nWe can use the `anova()` function providing the model and the hypothesis matrix.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nanova(fit) # the default\n#> \n#> Test of Moderators (coefficient 2):\n#> QM(df = 1) = 68.6500, p-val < .0001\nanova(fit, X = C)\n#> \n#> Hypotheses:                           \n#> 1:             intrcpt = 0 \n#> 2: intrcpt + exponline = 0 \n#> \n#> Results:\n#>    estimate     se    zval   pval \n#> 1:   0.2408 0.0440  5.4704 <.0001 \n#> 2:   0.7578 0.0442 17.1365 <.0001 \n#> \n#> Omnibus Test of Hypotheses:\n#> QM(df = 2) = 323.5856, p-val < .0001\n```\n:::\n\n\nNotice that is the same as the model without the intercept.\n\n## Likelihood Ratio Test (LRT)\n\nAs in standard regression modelling, we can also compare models using LRT. The `anova()` function will compute the LRT when two (nested) models are provided. In this case we compared a null (intercept-only) model with the model including the predictor.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# the null model\nfit0 <- rma(yi, vi, data = dat, method = \"REML\")\nanova(fit0, fit, refit = TRUE) # refit = TRUE because LRT with REML is not meaningful, using ML instead\n#> \n#>         df      AIC      BIC     AICc   logLik     LRT   pval       QE  tau^2 \n#> Full     3  53.1066  60.9222  53.3566 -23.5533                189.6112 0.0447 \n#> Reduced  2 104.9762 110.1866 105.0999 -50.4881 53.8696 <.0001 319.7111 0.1092 \n#>              R^2 \n#> Full             \n#> Reduced 59.0925%\n```\n:::\n\n\n## $R^2$\n\nThe $R^2$ value reported in the model output is not calculated as in standard regression analysis.\n\n$$\nR^2 = 1 - \\frac{\\tau^2_r}{\\tau^2}\n$$\n\nBasically is the percentage of heterogeneity reduction from the intercept-only model to the model including predictors.\n\nIn R:\n\n\n::: {.cell layout-align=\"center\"}\n\n```\n#> [1] 58.01751\n#> [1] 58.01751\n```\n:::\n\n\n## $R^2$\n\nDespite useful, the $R^2$ has some limitations:\n\n- @Lopez-Lopez2014-it showed that precise estimations require a large number of studies $k$ \n- Sometimes could results in negative values (usually truncated to zero)\n- Depends on the $\\tau^2$ estimator\n\nMore about $R^2$ and limitations can be found:\n\n- [https://www.metafor-project.org/doku.php/faq#for_mixed-effects_models_how_i](https://www.metafor-project.org/doku.php/faq#for_mixed-effects_models_how_i)\n- [https://www.metafor-project.org/doku.php/tips:ci_for_r2](https://www.metafor-project.org/doku.php/tips:ci_for_r2)\n\n## Numerical predictor\n\nThe same logic of simulating a meta-regression can be applied to numerical predictors. We still have $\\beta_0$ and $\\beta_1$ but $X$ has more levels. Let's simulate an impact of the average participants' age on the effect size.\n\n- $\\beta_0$ is the effect size when **age** is zero\n- $\\beta_1$ is the expected increase in the effect size for a unit increase in `age`\n\nHow we can choose plausible values for the parameters and parametrize the model correctly?\n\n## Parametrize $\\beta_0$\n\nThe intepretation (and the inference) of $\\beta_0$ is strongly dependent on the type of numerical predictor. An age of zero is (probably) empirically meaningless thus the  $\\beta_0$ is somehow not useful.\n\nWe can for example mean-center (or other type of centering procedure) moving the zero on a meaningful value.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nage <- 10:50 # the raw vector\nage0 <- age - mean(age) # centering on the mean\nage20 <- age - min(age) # centering on the minimum\n\nht(data.frame(age, age0, age20))\n#>    age age0 age20\n#> 1   10  -20     0\n#> 2   11  -19     1\n#> 3   12  -18     2\n#> 4   13  -17     3\n#> 5   14  -16     4\n#> 36  45   15    35\n#> 37  46   16    36\n#> 38  47   17    37\n#> 39  48   18    38\n#> 40  49   19    39\n#> 41  50   20    40\n```\n:::\n\n\n## Parametrize $\\beta_0$\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](meta-regression_files/figure-revealjs/unnamed-chunk-15-1.svg){fig-align='center' width=960}\n:::\n:::\n\n\n## Parametrize $\\beta_0$\n\nUsing different parametrizations will only affect the estimation (and the interpretation) of $\\beta_0$. Other parameters and indexes will be the same.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nk <- 100\nb0 <- 0.2 # effect size when age 0\nb1 <- 0.05 # slope (random for now)\nage <- round(runif(k, 20, 50)) # sampling from uniform distribution\ntau2r <- 0.05\nn <- 10 + rpois(k, 30 - 10)\n\nes <- b0 + b1 * age # raw\n\nage0 <- age - mean(age)\nage20 <- age - 20\n\ndat <- sim_studies(k = k, es = es, tau2 = tau2r, n1 = n, add = list(age = age, age0 = age0, age20 = age20))\n\nfit <- rma(yi, vi, mods = ~ age, data = dat)\nfit0 <- rma(yi, vi, mods = ~ age0, data = dat)\nfit20 <- rma(yi, vi, mods = ~ age20, data = dat)\n\n# showing the intercept\ncompare_rma(fit, fit0, fit20, extra_params = \"R2\") |> \n  round(3)\n#> fit: rma(yi = yi, vi = vi, mods = ~age, data = dat)\n#> fit0: rma(yi = yi, vi = vi, mods = ~age0, data = dat)\n#> fit20: rma(yi = yi, vi = vi, mods = ~age20, data = dat)\n#>                fit   fit0  fit20\n#> b (intrcpt)  0.108  1.918  1.157\n#> se           0.122  0.031  0.059\n#> zval         0.888 61.058 19.682\n#> pval         0.375  0.000  0.000\n#> ci.lb       -0.131  1.856  1.041\n#> ci.ub        0.348  1.980  1.272\n#> R2          87.687 87.687 87.687\n#> I2          33.594 33.594 33.594\n#> tau2         0.033  0.033  0.033\n\n  # showing the intercept\ncompare_rma(fit, fit0, fit20, b = \"age\", extra_params = \"R2\") |> \n  round(3)\n#> fit: rma(yi = yi, vi = vi, mods = ~age, data = dat)\n#> fit0: rma(yi = yi, vi = vi, mods = ~age0, data = dat)\n#> fit20: rma(yi = yi, vi = vi, mods = ~age20, data = dat)\n#>            fit   fit0  fit20\n#> b (age)  0.052  0.052  0.052\n#> se       0.003  0.003  0.003\n#> zval    15.356 15.356 15.356\n#> pval     0.000  0.000  0.000\n#> ci.lb    0.046  0.046  0.046\n#> ci.ub    0.059  0.059  0.059\n#> R2      87.687 87.687 87.687\n#> I2      33.594 33.594 33.594\n#> tau2     0.033  0.033  0.033\n```\n:::\n\n\n## Choosing $\\beta_1$\n\nThe core of the model is $\\beta_1$ that is the **age** effect. Compared to the categorical case where $\\beta_1$ is just the standardized difference between two conditions, with numerical $X$ choosing a meaningful $\\beta_1$ is more challenging.\n\nTwo (maybe more) strategies:\n\n- simulating a lot of effects sizes fixing $beta_0$ and $\\beta_1$ and see the expected range of $y_i$\n- fixing a certain $R^2$ and choose the $\\beta_1$ producing that $R^2$\n- ...\n\n## $\\beta_1$ by simulations\n\nA strategy could be to simulate from the generative model a large number of studies and see the expected range of effect size [@Gelman2020-tg, Chapter 5 and p. 97]. A large number of unplausible values suggest that the chosen $\\beta_1$ is probably not appropriate.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nk <- 1e3\nn <- 30\ntau2 <- 0\nx <- runif(k, 20, 50) # age\nb0 <- 0.1\nb1 <- c(0.001, 0.05, 0.2)\nesl <- lapply(b1, function(b) b0 + b*x)\ndatl <- lapply(esl, function(es) sim_studies(k = k, es = es, tau2 = tau2, n1 = n, add = list(x = x)))\nnames(datl) <- b1\ndat <- dplyr::bind_rows(datl, .id = \"b1\")\nht(dat)\n#> \n#>         b1   id      yi     vi n1 n2        x \n#> 1    0.001    1  0.1386 0.0777 30 30 36.64461 \n#> 2    0.001    2 -0.0254 0.0571 30 30 47.51239 \n#> 3    0.001    3  0.1603 0.0691 30 30 28.72855 \n#> 4    0.001    4  0.5369 0.0793 30 30 32.02046 \n#> 5    0.001    5 -0.6785 0.0687 30 30 48.38014 \n#> 2995   0.2  995  6.4789 0.0642 30 30 33.85572 \n#> 2996   0.2  996  7.0514 0.0529 30 30 34.38240 \n#> 2997   0.2  997  3.9459 0.0813 30 30 20.07518 \n#> 2998   0.2  998  6.8888 0.0652 30 30 35.04802 \n#> 2999   0.2  999  6.8392 0.0755 30 30 33.53124 \n#> 3000   0.2 1000  9.2417 0.0677 30 30 47.20710\n```\n:::\n\n\n## $\\beta_1$ by simulations\n\nClearly given the limited range of the $x$ variable (`age`) some $\\beta_1$ values are implausible leading to effect sizes that are out of a meaningful empirical range.\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](meta-regression_files/figure-revealjs/unnamed-chunk-18-1.svg){fig-align='center' width=960}\n:::\n:::\n\n\n## Fixing $R^2$\n\nWe can use the approach by @Lopez-Lopez2014-it where predictors $x$ are sampled from a standard normal distribution (or standardized). $\\beta_1$ is calculated as $\\beta_1 = \\sqrt{\\tau^2 R^2}$ and the residual heterogeneity as $\\tau^2_r = \\tau^2 - \\beta^2_1$.\n\n\n::: {.cell layout-align=\"center\"}\n\n:::\n\n\n## Fixing $R^2$\n\nWe can check the simulation approach:\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nk <- 1e3\n1 - tau2r/tau2\n#> [1] 0.4\nx <- rnorm(k)\nes <- b0 + b1 * x\ndat <- sim_studies(k, es, tau2r, n1 = 1e3, add = list(x = x))\nfit <- rma(yi, vi, data = dat, mods = ~x)\nsummary(fit)\n#> \n#> Mixed-Effects Model (k = 1000; tau^2 estimator: REML)\n#> \n#>    logLik   deviance        AIC        BIC       AICc   \n#> -567.3723  1134.7447  1140.7447  1155.4619  1140.7688   \n#> \n#> tau^2 (estimated amount of residual heterogeneity):     0.1805 (SE = 0.0082)\n#> tau (square root of estimated tau^2 value):             0.4249\n#> I^2 (residual heterogeneity / unaccounted variability): 98.90%\n#> H^2 (unaccounted variability / sampling variability):   91.31\n#> R^2 (amount of heterogeneity accounted for):            42.71%\n#> \n#> Test for Residual Heterogeneity:\n#> QE(df = 998) = 91327.1884, p-val < .0001\n#> \n#> Test of Moderators (coefficient 2):\n#> QM(df = 1) = 737.6183, p-val < .0001\n#> \n#> Model Results:\n#> \n#>          estimate      se     zval    pval   ci.lb   ci.ub      \n#> intrcpt    0.1084  0.0135   8.0214  <.0001  0.0819  0.1349  *** \n#> x          0.3617  0.0133  27.1591  <.0001  0.3356  0.3878  *** \n#> \n#> ---\n#> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n:::\n\n\n## $R^2$ using simulations\n\nThe results from @Lopez-Lopez2014-it (and also our previous simulation) suggested that we need a large number of studies for precise $R^2$ estimations. Let's check using simulations the sampling distribution of $R^2$ using a plausible meta-analysis scenario.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nk <- 40 # number of studies\nn <- 10 + rpois(k, 40 - 10) # sample size\ntau2 <- 0.05 # tau ~ 0.22\nR2 <- 0.3\nb0 <- 0.1\nb1_2 <- tau2 * R2\nb1 <- sqrt(b1_2)\ntau2r <- tau2 - b1_2\nnsim <- 1e3\n\nR2i <- rep(NA, nsim)\n\nfor(i in 1:nsim){\n  x <- rnorm(k)\n  dat <- sim_studies(k = k, es = b0 + b1*x, tau2 = tau2r, n1 = n, add = list(x))\n  fit <- rma(yi, vi, data = dat, mods = ~x)\n  R2i[i] <- fit$R2\n}\n```\n:::\n\n\n## $R^2$ using simulations\n\nWe estimated the true $R^2$ correctly but there is a lot of uncertainty with a plausible meta-analysis scenario. There are a lot of meta-analysis also with lower $k$ worsening the results.\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](meta-regression_files/figure-revealjs/unnamed-chunk-22-1.svg){fig-align='center' width=960}\n:::\n:::\n\n\n## References <button class=\"btn\"><i class=\"fa fa-download\"></i><a href=\"data:text/x-bibtex;base64,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\" download=\"refs_to_download.bib\"> Download .bib file</a></button> {.refs}\n\n::: {#refs}\n:::",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}