{
  "hash": "df6466cb2f292ed4fb471e41434b978e",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Meta-regression\"\n---\n\n\n\n\n\n\n# Meta-analysis as (weighted) linear regression {.section}\n\n## MA as (weighted) linear regression\n\nBoth the EE and RE model can be seen as standard (weighted) linear regression models. Precisely, there is a difference in fitting a meta-analysis using `lm` or `lme4::lmer()` and `rma` (see [https://www.metafor-project.org/doku.php/tips:rma_vs_lm_lme_lmer](https://www.metafor-project.org/doku.php/tips:rma_vs_lm_lme_lmer)).\n\n. . .\n\nBeyond these differences a general the EE and RE models are intercept-only linear regressions.\n\n$$\n\\boldsymbol{Y} = \\mathbf{X}\\boldsymbol{\\beta} + \\boldsymbol{\\epsilon}\n$$\n\nThe EE model:\n\n$$\ny_i = \\beta_0 + \\epsilon_i \n$$\n\nThe RE model:\n\n$$\ny_i = \\beta_0 + \\beta_{0_i} + \\epsilon_i \n$$\n\n## MA as (weighted) linear regression\n\nIn the EE model $\\beta_0$ is $\\theta$ and $\\epsilon_i \\sim \\mathcal{N}(0, \\sigma^2_i)$\n\n$$\ny_i = \\beta_0 + \\epsilon_i \n$$\n\nIn the RE model $\\beta_0$ is $\\mu_{\\theta}$ and $\\beta_{0_i}$ are the $\\delta_i$.\n\n## Explaining $\\tau^2$\n\nSo far we simply assumed $\\tau^2 = 0$ (for the EE model) or estimated it using the RE model.\n\n. . .\n\nWe can extend the intercept-only meta-analysis by including study-level predictors (as in standard linear regression) to explain the estimated true heterogeneity.\n\n## Explaining $\\tau^2$\n\nLet's make an example where we simulate a meta-analysis with $k = 100$ studies. Beyond the effect size, we extracted an experimental condition where 50 studies where lab-based experiments $x_{lab}$ and 50 studies where online experiments.\n\nWe assume that there could be a **lab effect** thus we included a predictor in the model.\n\n\n::: {.cell}\n\n:::\n\n\n## Explaining $\\tau^2$\n\nNow the model have a predictor $x$ (the type of experiment) and two parameters $\\beta_0$ and $\\beta_1$. Depending on the contrast coding (default to `contr.treatment()` in R) the $\\beta_0$ is different. Coding `exp` as 0 for lab-based experiments and 1 for online experiments:\n\n$$\ny_i = \\beta_0 + \\beta_1X_{1_i} + \\epsilon_i\n$$\n\n$$\ny_{\\text{lab}_i} = \\beta_0 + \\epsilon_i\n$$\n\n$$\ny_{\\text{online}_i} = \\beta_0 + \\beta_1 + \\epsilon_i\n$$\n\n## Explaining $\\tau^2$\n\nWhat is missing is the random-effect. Basically we still have $\\tau^2$ determining the $\\delta_i \\sim \\mathcal{N}(0, \\tau^2)$ but now is the residual $\\tau^2_r$. The heterogeneity after including the predictor.\n\n$$\ny_i = \\beta_0 + \\beta_{0_i} + \\beta_1X_{1_i} + \\epsilon_i\n$$ {#eq-metareg-cat}\n\n$$\n\\beta_{0_i} \\sim \\mathcal{N}(0, \\tau^2_r)\n$$\n\nClearly the difference between $\\tau^2$ (the total heterogeneity) and $\\tau^2_r$ (residual heterogeneity) is an index of the impact of $X$.\n\n## Simulating the $X$ effect\n\nTo simulate a meta-regression we just need to choose the parameters values ($\\beta_0$ and $\\beta_1$) and implement @eq-metareg-cat. Using treatment coding, $\\beta_0$ is the effect size when $X = 0$ (i.e., lab-based experiments) and $\\beta_1$ is the difference between lab and online experiments.\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n\n```\n       exp exp_dummy  es\n1      lab         0 0.3\n2      lab         0 0.3\n3      lab         0 0.3\n4      lab         0 0.3\n5      lab         0 0.3\n95  online         1 0.8\n96  online         1 0.8\n97  online         1 0.8\n98  online         1 0.8\n99  online         1 0.8\n100 online         1 0.8\n```\n\n\n:::\n:::\n\n\n## Simulating the $X$ effects\n\nNow we can use the `sim_studies()` function as usual. The difference is that `es` is no longer a single value but a vector (with different values according to the $X$ level) and `tau2` is $\\tau^2_r$ (this the leftover heterogeneity after including the $X$ effect)\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n\n```\n\n     id     yi     vi n1 n2    exp \n1     1 0.4847 0.0570 44 44    lab \n2     2 0.7244 0.0739 33 33    lab \n3     3 0.5974 0.0650 42 42    lab \n4     4 0.4499 0.0422 43 43    lab \n5     5 0.6217 0.0663 44 44    lab \n95   95 0.6637 0.0376 51 51 online \n96   96 0.9044 0.0579 39 39 online \n97   97 1.3943 0.0698 29 29 online \n98   98 0.7746 0.0360 44 44 online \n99   99 0.7996 0.0837 32 32 online \n100 100 0.7638 0.0448 39 39 online \n```\n\n\n:::\n:::\n\n\n## Fitting a meta-regression Model\n\nTo fit a meta-regression we still use the `metafor::rma()` function, adding the `mods = ~` parameter with the model formula (same as the right-hand side of a `y ~ x` call in `lm`). The name of the predictor in the formula need to match a column of the `data = ` dataframe.\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n\n```\n\nMixed-Effects Model (k = 100; tau^2 estimator: REML)\n\n  logLik  deviance       AIC       BIC      AICc   \n-30.0314   60.0629   66.0629   73.8178   66.3182   \n\ntau^2 (estimated amount of residual heterogeneity):     0.0559 (SE = 0.0152)\ntau (square root of estimated tau^2 value):             0.2365\nI^2 (residual heterogeneity / unaccounted variability): 52.95%\nH^2 (unaccounted variability / sampling variability):   2.13\nR^2 (amount of heterogeneity accounted for):            50.53%\n\nTest for Residual Heterogeneity:\nQE(df = 98) = 207.6566, p-val < .0001\n\nTest of Moderators (coefficient 2):\nQM(df = 1) = 53.1020, p-val < .0001\n\nModel Results:\n\n           estimate      se    zval    pval   ci.lb   ci.ub      \nintrcpt      0.3503  0.0458  7.6404  <.0001  0.2604  0.4402  *** \nexponline    0.4767  0.0654  7.2871  <.0001  0.3485  0.6049  *** \n\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n\n\n:::\n:::\n\n\n## Intepreting a meta-regression Model\n\nThe output is similar to the RE model with few additions:\n\n- Everything related to the heterogeneity ($H^2$, $I^2$, $Q$, etc.) is now about **residual heterogeneity**\n- There is the (pseudo) $R^2$\n- There is an overall test for the moderators $Q_M$\n- There is a section (similar to standard regression models) with the estimated parameters, standard error and Wald test\n\n## Model parameters\n\n`intrcpt` and `exponline` are the estimates of $\\beta_0$ and $\\beta_1$. The interpretation depends on the scale of the effect size and the contrast coding.\n\nWe can plot the model results using the `metafor::regplot()`^[The functions is made for numerical variables thus is less appropriate for categorical variables].\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](meta-regression_files/figure-revealjs/unnamed-chunk-7-1.png){width=960}\n:::\n:::\n\n\n## Omnibus Moderator Test\n\nThe `Test of Moderators` section report the so-called omnibus test for model coeffiecients. Is a simultaneous test for 1 or more coefficients where $H_0: \\beta_j = 0$.\n\nIn this case, **coefficient 2** means that we are testing only the 2nd coefficient $\\beta_1$. By default, the intercept is ignored. In fact, the `exponline` line and the omnibus test are the same (the $\\chi^2$ is just the $z^2$)\n\n\n::: {.cell}\n\n```\n## Test of Moderators (coefficient 2):\n## QM(df = 1) = 53.1020, p-val < .0001\n##            estimate      se    zval    pval   ci.lb   ci.ub      \n## intrcpt      0.3503  0.0458  7.6404  <.0001  0.2604  0.4402  *** \n## exponline    0.4767  0.0654  7.2871  <.0001  0.3485  0.6049  ***\n```\n:::\n\n\n## General Linear Hypotheses Testing (GLHT)\n\nWe can also test any combination of parameters. For example we could test if lab-based experiments and online experiments are both different from 0. This is the same as fitting a model without the intercept^[see [https://www.metafor-project.org/doku.php/tips:models_with_or_without_intercept](https://www.metafor-project.org/doku.php/tips:models_with_or_without_intercept) on removing the intercept] thus estimating the cell means [see @Schad2020-ht].\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# now we are testing two coefficients\nfit_no_int <- rma(yi, vi, mods = ~ 0 + exp, data = dat)\nfit_no_int\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nMixed-Effects Model (k = 100; tau^2 estimator: REML)\n\ntau^2 (estimated amount of residual heterogeneity):     0.0559 (SE = 0.0152)\ntau (square root of estimated tau^2 value):             0.2365\nI^2 (residual heterogeneity / unaccounted variability): 52.95%\nH^2 (unaccounted variability / sampling variability):   2.13\n\nTest for Residual Heterogeneity:\nQE(df = 98) = 207.6566, p-val < .0001\n\nTest of Moderators (coefficients 1:2):\nQM(df = 2) = 372.5111, p-val < .0001\n\nModel Results:\n\n           estimate      se     zval    pval   ci.lb   ci.ub      \nexplab       0.3503  0.0458   7.6404  <.0001  0.2604  0.4402  *** \nexponline    0.8270  0.0467  17.7238  <.0001  0.7355  0.9184  *** \n\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n\n\n:::\n:::\n\n\n## General Linear Hypotheses Testing (GLHT)\n\nA more elegant way is by using the GLHT framework. Basically we provide a contrast matrix expressing linear combinations of model parameters to be tested. In our case $\\text{lab} = \\beta_0 = 0$ and $\\text{online} = \\beta_0 + \\beta_1 = 0$.\n\nPractically, the matrix formulation is the following:\n\n$$\n\\begin{pmatrix}  \n1 & 0 \\\\\n1 & 1\n\\end{pmatrix}\n\\begin{pmatrix}  \n\\beta_0\\\\\n\\beta_1\n\\end{pmatrix}\n=\n\\begin{pmatrix}  \n0\\\\\n0\n\\end{pmatrix}\n$$\n\nIn R:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nC <- rbind(c(1, 0), c(1, 1))\nB <- coef(fit)\nC %*% B # same as coef(fit)[1] and coef(fit)[1] +  coef(fit)[2]\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n          [,1]\n[1,] 0.3503016\n[2,] 0.8269936\n```\n\n\n:::\n:::\n\n\n## General Linear Hypotheses Testing (GLHT)\n\nWe can use the `anova()` function providing the model and the hypothesis matrix.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nanova(fit) # the default\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nTest of Moderators (coefficient 2):\nQM(df = 1) = 53.1020, p-val < .0001\n```\n\n\n:::\n\n```{.r .cell-code}\nanova(fit, X = C)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nHypotheses:                           \n1:             intrcpt = 0 \n2: intrcpt + exponline = 0 \n\nResults:\n   estimate     se    zval   pval \n1:   0.3503 0.0458  7.6404 <.0001 \n2:   0.8270 0.0467 17.7238 <.0001 \n\nOmnibus Test of Hypotheses:\nQM(df = 2) = 372.5111, p-val < .0001\n```\n\n\n:::\n:::\n\n\nNotice that is the same as the model without the intercept.\n\n## Likelihood Ratio Test (LRT)\n\nAs in standard regression modelling, we can also compare models using LRT. The `anova()` function will compute the LRT when two (nested) models are provided. In this case we compared a null (intercept-only) model with the model including the predictor.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# the null model\nfit0 <- rma(yi, vi, data = dat, method = \"REML\")\nanova(fit0, fit, refit = TRUE) # refit = TRUE because LRT with REML is not meaningful, using ML instead\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n        df      AIC      BIC     AICc   logLik     LRT   pval       QE  tau^2 \nFull     3  65.2473  73.0628  65.4973 -29.6237                207.6566 0.0538 \nReduced  2 106.0854 111.2958 106.2092 -51.0427 42.8381 <.0001 325.8480 0.1114 \n             R^2 \nFull             \nReduced 51.7500% \n```\n\n\n:::\n:::\n\n\n## $R^2$\n\nThe $R^2$ value reported in the model output is not calculated as in standard regression analysis.\n\n$$\nR^2 = 1 - \\frac{\\tau^2_r}{\\tau^2}\n$$\n\nBasically is the percentage of heterogeneity reduction from the intercept-only model to the model including predictors.\n\nIn R:\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 50.52961\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 50.52961\n```\n\n\n:::\n:::\n\n\n## $R^2$\n\nDespite useful, the $R^2$ has some limitations:\n\n- @Lopez-Lopez2014-it showed that precise estimations require a large number of studies $k$ \n- Sometimes could results in negative values (usually truncated to zero)\n- Depends on the $\\tau^2$ estimator\n\nMore about $R^2$ and limitations can be found:\n\n- [https://www.metafor-project.org/doku.php/faq#for_mixed-effects_models_how_i](https://www.metafor-project.org/doku.php/faq#for_mixed-effects_models_how_i)\n- [https://www.metafor-project.org/doku.php/tips:ci_for_r2](https://www.metafor-project.org/doku.php/tips:ci_for_r2)\n\n## Numerical predictor\n\nThe same logic of simulating a meta-regression can be applied to numerical predictors. We still have $\\beta_0$ and $\\beta_1$ but $X$ has more levels. Let's simulate an impact of the average participants' age on the effect size.\n\n- $\\beta_0$ is the effect size when **age** is zero\n- $\\beta_1$ is the expected increase in the effect size for a unit increase in `age`\n\nHow we can choose plausible values for the parameters and parametrize the model correctly?\n\n## Parametrize $\\beta_0$\n\nThe intepretation (and the inference) of $\\beta_0$ is strongly dependent on the type of numerical predictor. An age of zero is (probably) empirically meaningless thus the  $\\beta_0$ is somehow not useful.\n\nWe can for example mean-center (or other type of centering procedure) moving the zero on a meaningful value.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nage <- 10:50 # the raw vector\nage0 <- age - mean(age) # centering on the mean\nage20 <- age - min(age) # centering on the minimum\n\nht(data.frame(age, age0, age20))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   age age0 age20\n1   10  -20     0\n2   11  -19     1\n3   12  -18     2\n4   13  -17     3\n5   14  -16     4\n36  45   15    35\n37  46   16    36\n38  47   17    37\n39  48   18    38\n40  49   19    39\n41  50   20    40\n```\n\n\n:::\n:::\n\n\n## Parametrize $\\beta_0$\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](meta-regression_files/figure-revealjs/unnamed-chunk-15-1.png){width=960}\n:::\n:::\n\n\n## Parametrize $\\beta_0$\n\nUsing different parametrizations will only affect the estimation (and the interpretation) of $\\beta_0$. Other parameters and indexes will be the same.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nk <- 100\nb0 <- 0.2 # effect size when age 0\nb1 <- 0.05 # slope (random for now)\nage <- round(runif(k, 20, 50)) # sampling from uniform distribution\ntau2r <- 0.05\nn <- 10 + rpois(k, 30 - 10)\n\nes <- b0 + b1 * age # raw\n\nage0 <- age - mean(age)\nage20 <- age - 20\n\ndat <- sim_studies(k = k, es = es, tau2 = tau2r, n1 = n, add = list(age = age, age0 = age0, age20 = age20))\n\nfit <- rma(yi, vi, mods = ~ age, data = dat)\nfit0 <- rma(yi, vi, mods = ~ age0, data = dat)\nfit20 <- rma(yi, vi, mods = ~ age20, data = dat)\n\n# showing the intercept\ncompare_rma(fit, fit0, fit20, extra_params = \"R2\") |> \n  round(3)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nfit: rma(yi = yi, vi = vi, mods = ~age, data = dat)\nfit0: rma(yi = yi, vi = vi, mods = ~age0, data = dat)\nfit20: rma(yi = yi, vi = vi, mods = ~age20, data = dat)\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n               fit   fit0  fit20\nb (intrcpt)  0.177  1.909  1.159\nse           0.157  0.038  0.076\nzval         1.130 50.372 15.308\npval         0.259  0.000  0.000\nci.lb       -0.130  1.835  1.011\nci.ub        0.484  1.983  1.308\nR2          70.229 70.229 70.229\nI2          54.369 54.369 54.369\ntau2         0.077  0.077  0.077\n```\n\n\n:::\n\n```{.r .cell-code}\n  # showing the intercept\ncompare_rma(fit, fit0, fit20, b = \"age\", extra_params = \"R2\") |> \n  round(3)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nfit: rma(yi = yi, vi = vi, mods = ~age, data = dat)\nfit0: rma(yi = yi, vi = vi, mods = ~age0, data = dat)\nfit20: rma(yi = yi, vi = vi, mods = ~age20, data = dat)\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n           fit   fit0  fit20\nb (age)  0.049  0.049  0.049\nse       0.004  0.004  0.004\nzval    11.366 11.366 11.366\npval     0.000  0.000  0.000\nci.lb    0.041  0.041  0.041\nci.ub    0.058  0.058  0.058\nR2      70.229 70.229 70.229\nI2      54.369 54.369 54.369\ntau2     0.077  0.077  0.077\n```\n\n\n:::\n:::\n\n\n## Choosing $\\beta_1$\n\nThe core of the model is $\\beta_1$ that is the **age** effect. Compared to the categorical case where $\\beta_1$ is just the standardized difference between two conditions, with numerical $X$ choosing a meaningful $\\beta_1$ is more challenging.\n\nTwo (maybe more) strategies:\n\n- simulating a lot of effects sizes fixing $beta_0$ and $\\beta_1$ and see the expected range of $y_i$\n- fixing a certain $R^2$ and choose the $\\beta_1$ producing that $R^2$\n- ...\n\n## $\\beta_1$ by simulations\n\nA strategy could be to simulate from the generative model a large number of studies and see the expected range of effect size [@Gelman2020-tg, Chapter 5 and p. 97]. A large number of unplausible values suggest that the chosen $\\beta_1$ is probably not appropriate.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nk <- 1e3\nn <- 30\ntau2 <- 0\nx <- runif(k, 20, 50) # age\nb0 <- 0.1\nb1 <- c(0.001, 0.05, 0.2)\nesl <- lapply(b1, function(b) b0 + b*x)\ndatl <- lapply(esl, function(es) sim_studies(k = k, es = es, tau2 = tau2, n1 = n, add = list(x = x)))\nnames(datl) <- b1\ndat <- dplyr::bind_rows(datl, .id = \"b1\")\nht(dat)\n## \n##         b1   id      yi     vi n1 n2        x \n## 1    0.001    1  0.0119 0.0689 30 30 25.39193 \n## 2    0.001    2 -0.0592 0.0626 30 30 46.96575 \n## 3    0.001    3 -0.0670 0.0694 30 30 44.98784 \n## 4    0.001    4  0.6036 0.0813 30 30 21.47130 \n## 5    0.001    5 -0.1416 0.0833 30 30 27.83832 \n## 2995   0.2  995  9.5025 0.0380 30 30 43.84276 \n## 2996   0.2  996  7.4130 0.0663 30 30 37.10261 \n## 2997   0.2  997  9.4021 0.0712 30 30 46.46504 \n## 2998   0.2  998  4.5550 0.0832 30 30 21.37765 \n## 2999   0.2  999  5.4775 0.0750 30 30 27.05406 \n## 3000   0.2 1000  5.6702 0.0554 30 30 29.61812\n```\n:::\n\n\n## $\\beta_1$ by simulations\n\nClearly given the limited range of the $x$ variable (`age`) some $\\beta_1$ values are implausible leading to effect sizes that are out of a meaningful empirical range.\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](meta-regression_files/figure-revealjs/unnamed-chunk-18-1.png){width=960}\n:::\n:::\n\n\n## Fixing $R^2$\n\nWe can use the approach by @Lopez-Lopez2014-it where predictors $x$ are sampled from a standard normal distribution (or standardized). $\\beta_1$ is calculated as $\\beta_1 = \\sqrt{\\tau^2 R^2}$ and the residual heterogeneity as $\\tau^2_r = \\tau^2 - \\beta^2_1$.\n\n\n::: {.cell}\n\n:::\n\n\n## Fixing $R^2$\n\nWe can check the simulation approach:\n\n::: {.cell}\n\n```{.r .cell-code}\nk <- 1e3\n1 - tau2r/tau2\n## [1] 0.4\nx <- rnorm(k)\nes <- b0 + b1 * x\ndat <- sim_studies(k, es, tau2r, n1 = 1e3, add = list(x = x))\nfit <- rma(yi, vi, data = dat, mods = ~x)\nsummary(fit)\n## \n## Mixed-Effects Model (k = 1000; tau^2 estimator: REML)\n## \n##    logLik   deviance        AIC        BIC       AICc   \n## -521.1960  1042.3919  1048.3919  1063.1092  1048.4161   \n## \n## tau^2 (estimated amount of residual heterogeneity):     0.1644 (SE = 0.0074)\n## tau (square root of estimated tau^2 value):             0.4055\n## I^2 (residual heterogeneity / unaccounted variability): 98.80%\n## H^2 (unaccounted variability / sampling variability):   83.36\n## R^2 (amount of heterogeneity accounted for):            42.50%\n## \n## Test for Residual Heterogeneity:\n## QE(df = 998) = 83263.7030, p-val < .0001\n## \n## Test of Moderators (coefficient 2):\n## QM(df = 1) = 730.4726, p-val < .0001\n## \n## Model Results:\n## \n##          estimate      se     zval    pval   ci.lb   ci.ub      \n## intrcpt    0.1062  0.0129   8.2329  <.0001  0.0809  0.1315  *** \n## x          0.3531  0.0131  27.0273  <.0001  0.3275  0.3787  *** \n## \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n:::\n\n\n## $R^2$ using simulations\n\nThe results from @Lopez-Lopez2014-it (and also our previous simulation) suggested that we need a large number of studies for precise $R^2$ estimations. Let's check using simulations the sampling distribution of $R^2$ using a plausible meta-analysis scenario.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nk <- 40 # number of studies\nn <- 10 + rpois(k, 40 - 10) # sample size\ntau2 <- 0.05 # tau ~ 0.22\nR2 <- 0.3\nb0 <- 0.1\nb1_2 <- tau2 * R2\nb1 <- sqrt(b1_2)\ntau2r <- tau2 - b1_2\nnsim <- 1e3\n\nR2i <- rep(NA, nsim)\n\nfor(i in 1:nsim){\n  x <- rnorm(k)\n  dat <- sim_studies(k = k, es = b0 + b1*x, tau2 = tau2r, n1 = n, add = list(x))\n  fit <- rma(yi, vi, data = dat, mods = ~x)\n  R2i[i] <- fit$R2\n}\n```\n:::\n\n\n## $R^2$ using simulations\n\nWe estimated the true $R^2$ correctly but there is a lot of uncertainty with a plausible meta-analysis scenario. There are a lot of meta-analysis also with lower $k$ worsening the results.\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](meta-regression_files/figure-revealjs/unnamed-chunk-22-1.png){width=960}\n:::\n:::\n\n\n## References\n\n::: {#refs}\n:::",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}