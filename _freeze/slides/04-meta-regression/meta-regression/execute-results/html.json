{
  "hash": "369fe1ec0ea91eebc292d2f252f47113",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Meta-regression\"\n---\n\n\n\n\n\n\n# Meta-analysis as (weighted) linear regression {.section}\n\n## MA as (weighted) linear regression\n\nBoth the EE and RE model can be seen as standard (weighted) linear regression models. Precisely, there is a difference in fitting a meta-analysis using `lm` or `lme4::lmer()` and `rma` (see [https://www.metafor-project.org/doku.php/tips:rma_vs_lm_lme_lmer](https://www.metafor-project.org/doku.php/tips:rma_vs_lm_lme_lmer)).\n\n. . .\n\nBeyond these differences a general the EE and RE models are intercept-only linear regressions.\n\n$$\n\\boldsymbol{Y} = \\mathbf{X}\\boldsymbol{\\beta} + \\boldsymbol{\\epsilon}\n$$\n\nThe EE model:\n\n$$\ny_i = \\beta_0 + \\epsilon_i \n$$\n\nThe RE model:\n\n$$\ny_i = \\beta_0 + \\beta_{0_i} + \\epsilon_i \n$$\n\n## MA as (weighted) linear regression\n\nIn the EE model $\\beta_0$ is $\\theta$ and $\\epsilon_i \\sim \\mathcal{N}(0, \\sigma^2_i)$\n\n$$\ny_i = \\beta_0 + \\epsilon_i \n$$\n\nIn the RE model $\\beta_0$ is $\\mu_{\\theta}$ and $\\beta_{0_i}$ are the $\\delta_i$.\n\n## Explaining $\\tau^2$\n\nSo far we simply assumed $\\tau^2 = 0$ (for the EE model) or estimated it using the RE model.\n\n. . .\n\nWe can extend the intercept-only meta-analysis by including study-level predictors (as in standard linear regression) to explain the estimated true heterogeneity.\n\n## Explaining $\\tau^2$\n\nLet's make an example where we simulate a meta-analysis with $k = 100$ studies. Beyond the effect size, we extracted an experimental condition where 50 studies where lab-based experiments $x_{lab}$ and 50 studies where online experiments.\n\nWe assume that there could be a **lab effect** thus we included a predictor in the model.\n\n\n::: {.cell layout-align=\"center\"}\n\n:::\n\n\n## Explaining $\\tau^2$\n\nNow the model have a predictor $x$ (the type of experiment) and two parameters $\\beta_0$ and $\\beta_1$. Depending on the contrast coding (default to `contr.treatment()` in R) the $\\beta_0$ is different. Coding `exp` as 0 for lab-based experiments and 1 for online experiments:\n\n$$\ny_i = \\beta_0 + \\beta_1X_{1_i} + \\epsilon_i\n$$\n\n$$\ny_{\\text{lab}_i} = \\beta_0 + \\epsilon_i\n$$\n\n$$\ny_{\\text{online}_i} = \\beta_0 + \\beta_1 + \\epsilon_i\n$$\n\n## Explaining $\\tau^2$\n\nWhat is missing is the random-effect. Basically we still have $\\tau^2$ determining the $\\delta_i \\sim \\mathcal{N}(0, \\tau^2)$ but now is the residual $\\tau^2_r$. The heterogeneity after including the predictor.\n\n$$\ny_i = \\beta_0 + \\beta_{0_i} + \\beta_1X_{1_i} + \\epsilon_i\n$$ {#eq-metareg-cat}\n\n$$\n\\beta_{0_i} \\sim \\mathcal{N}(0, \\tau^2_r)\n$$\n\nClearly the difference between $\\tau^2$ (the total heterogeneity) and $\\tau^2_r$ (residual heterogeneity) is an index of the impact of $X$.\n\n## Simulating the $X$ effect\n\nTo simulate a meta-regression we just need to choose the parameters values ($\\beta_0$ and $\\beta_1$) and implement @eq-metareg-cat. Using treatment coding, $\\beta_0$ is the effect size when $X = 0$ (i.e., lab-based experiments) and $\\beta_1$ is the difference between lab and online experiments.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nb0 <- 0.3 # lab-based effect size\nb1 <- 0.5 # online - lab-based --> online = b0 + b1\nexp_dummy <- ifelse(exp == \"lab\", 0, 1) # dummy version\nes <- b0 + b1 * exp_dummy\nht(data.frame(exp, exp_dummy, es))\n#>        exp exp_dummy  es\n#> 1      lab         0 0.3\n#> 2      lab         0 0.3\n#> 3      lab         0 0.3\n#> 4      lab         0 0.3\n#> 5      lab         0 0.3\n#> 95  online         1 0.8\n#> 96  online         1 0.8\n#> 97  online         1 0.8\n#> 98  online         1 0.8\n#> 99  online         1 0.8\n#> 100 online         1 0.8\n```\n:::\n\n\n## Simulating the $X$ effects\n\nNow we can use the `sim_studies()` function as usual. The difference is that `es` is no longer a single value but a vector (with different values according to the $X$ level) and `tau2` is $\\tau^2_r$ (this the leftover heterogeneity after including the $X$ effect)\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ntau2r <- 0.05 # residual heterogeneity\ndat <- sim_studies(k = k, es = es, tau2 = tau2r, n1 = n, add = list(exp = exp))\nht(dat)\n#> \n#>      id      yi     vi n1 n2    exp \n#> 1     1  0.5164 0.0705 34 34    lab \n#> 2     2 -0.2138 0.0587 34 34    lab \n#> 3     3 -0.1692 0.0562 35 35    lab \n#> 4     4  0.2356 0.0529 38 38    lab \n#> 5     5  0.2990 0.0565 38 38    lab \n#> 95   95  0.9620 0.0374 54 54 online \n#> 96   96  0.8478 0.0440 36 36 online \n#> 97   97  0.9840 0.0423 40 40 online \n#> 98   98  0.1730 0.0332 49 49 online \n#> 99   99  0.6717 0.0692 34 34 online \n#> 100 100  0.6460 0.0472 38 38 online\n```\n:::\n\n\n## Fitting a meta-regression Model\n\nTo fit a meta-regression we still use the `metafor::rma()` function, adding the `mods = ~` parameter with the model formula (same as the right-hand side of a `y ~ x` call in `lm`). The name of the predictor in the formula need to match a column of the `data = ` dataframe.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nfit <- rma(yi, vi, mods = ~ exp, data = dat, method = \"REML\")\nsummary(fit)\n#> \n#> Mixed-Effects Model (k = 100; tau^2 estimator: REML)\n#> \n#>   logLik  deviance       AIC       BIC      AICc   \n#> -20.1169   40.2338   46.2338   53.9887   46.4891   \n#> \n#> tau^2 (estimated amount of residual heterogeneity):     0.0396 (SE = 0.0126)\n#> tau (square root of estimated tau^2 value):             0.1990\n#> I^2 (residual heterogeneity / unaccounted variability): 45.03%\n#> H^2 (unaccounted variability / sampling variability):   1.82\n#> R^2 (amount of heterogeneity accounted for):            62.07%\n#> \n#> Test for Residual Heterogeneity:\n#> QE(df = 98) = 178.0054, p-val < .0001\n#> \n#> Test of Moderators (coefficient 2):\n#> QM(df = 1) = 74.2979, p-val < .0001\n#> \n#> Model Results:\n#> \n#>            estimate      se    zval    pval   ci.lb   ci.ub      \n#> intrcpt      0.2707  0.0425  6.3618  <.0001  0.1873  0.3541  *** \n#> exponline    0.5137  0.0596  8.6196  <.0001  0.3969  0.6305  *** \n#> \n#> ---\n#> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n:::\n\n\n## Intepreting a meta-regression Model\n\nThe output is similar to the RE model with few additions:\n\n- Everything related to the heterogeneity ($H^2$, $I^2$, $Q$, etc.) is now about **residual heterogeneity**\n- There is the (pseudo) $R^2$\n- There is an overall test for the moderators $Q_M$\n- There is a section (similar to standard regression models) with the estimated parameters, standard error and Wald test\n\n## Model parameters\n\n`intrcpt` and `exponline` are the estimates of $\\beta_0$ and $\\beta_1$. The interpretation depends on the scale of the effect size and the contrast coding.\n\nWe can plot the model results using the `metafor::regplot()`^[The functions is made for numerical variables thus is less appropriate for categorical variables].\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nregplot(fit)\n```\n\n::: {.cell-output-display}\n![](meta-regression_files/figure-revealjs/unnamed-chunk-7-1.svg){fig-align='center' width=960}\n:::\n:::\n\n\n## Omnibus Moderator Test\n\nThe `Test of Moderators` section report the so-called omnibus test for model coeffiecients. Is a simultaneous test for 1 or more coefficients where $H_0: \\beta_j = 0$.\n\nIn this case, **coefficient 2** means that we are testing only the 2nd coefficient $\\beta_1$. By default, the intercept is ignored. In fact, the `exponline` line and the omnibus test are the same (the $\\chi^2$ is just the $z^2$)\n\n\n::: {.cell layout-align=\"center\"}\n\n```\n#> Test of Moderators (coefficient 2):\n#> QM(df = 1) = 74.2979, p-val < .0001\n#>            estimate      se    zval    pval   ci.lb   ci.ub      \n#> intrcpt      0.2707  0.0425  6.3618  <.0001  0.1873  0.3541  *** \n#> exponline    0.5137  0.0596  8.6196  <.0001  0.3969  0.6305  ***\n```\n:::\n\n\n## General Linear Hypotheses Testing (GLHT)\n\nWe can also test any combination of parameters. For example we could test if lab-based experiments and online experiments are both different from 0. This is the same as fitting a model without the intercept^[see [https://www.metafor-project.org/doku.php/tips:models_with_or_without_intercept](https://www.metafor-project.org/doku.php/tips:models_with_or_without_intercept) on removing the intercept] thus estimating the cell means [see @Schad2020-ht].\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# now we are testing two coefficients\nfit_no_int <- rma(yi, vi, mods = ~ 0 + exp, data = dat)\n```\n:::\n\n\n## General Linear Hypotheses Testing (GLHT)\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nfit_no_int\n#> \n#> Mixed-Effects Model (k = 100; tau^2 estimator: REML)\n#> \n#> tau^2 (estimated amount of residual heterogeneity):     0.0396 (SE = 0.0126)\n#> tau (square root of estimated tau^2 value):             0.1990\n#> I^2 (residual heterogeneity / unaccounted variability): 45.03%\n#> H^2 (unaccounted variability / sampling variability):   1.82\n#> \n#> Test for Residual Heterogeneity:\n#> QE(df = 98) = 178.0054, p-val < .0001\n#> \n#> Test of Moderators (coefficients 1:2):\n#> QM(df = 2) = 393.8059, p-val < .0001\n#> \n#> Model Results:\n#> \n#>            estimate      se     zval    pval   ci.lb   ci.ub      \n#> explab       0.2707  0.0425   6.3618  <.0001  0.1873  0.3541  *** \n#> exponline    0.7844  0.0417  18.7972  <.0001  0.7026  0.8662  *** \n#> \n#> ---\n#> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n:::\n\n\n## General Linear Hypotheses Testing (GLHT)\n\nA more elegant way is by using the GLHT framework. Basically we provide a contrast matrix expressing linear combinations of model parameters to be tested. In our case $\\text{lab} = \\beta_0 = 0$ and $\\text{online} = \\beta_0 + \\beta_1 = 0$.\n\nPractically, the matrix formulation is the following:\n\n$$\n\\begin{pmatrix}  \n1 & 0 \\\\\n1 & 1\n\\end{pmatrix}\n\\begin{pmatrix}  \n\\beta_0\\\\\n\\beta_1\n\\end{pmatrix}\n=\n\\begin{pmatrix}  \n0\\\\\n0\n\\end{pmatrix}\n$$\n\nIn R:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nC <- rbind(c(1, 0), c(1, 1))\nB <- coef(fit)\nC %*% B # same as coef(fit)[1] and coef(fit)[1] +  coef(fit)[2]\n#>           [,1]\n#> [1,] 0.2706839\n#> [2,] 0.7843734\n```\n:::\n\n\n## General Linear Hypotheses Testing (GLHT)\n\nWe can use the `anova()` function providing the model and the hypothesis matrix.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nanova(fit) # the default\n#> \n#> Test of Moderators (coefficient 2):\n#> QM(df = 1) = 74.2979, p-val < .0001\nanova(fit, X = C)\n#> \n#> Hypotheses:                           \n#> 1:             intrcpt = 0 \n#> 2: intrcpt + exponline = 0 \n#> \n#> Results:\n#>    estimate     se    zval   pval \n#> 1:   0.2707 0.0425  6.3618 <.0001 \n#> 2:   0.7844 0.0417 18.7972 <.0001 \n#> \n#> Omnibus Test of Hypotheses:\n#> QM(df = 2) = 393.8059, p-val < .0001\n```\n:::\n\n\nNotice that is the same as the model without the intercept.\n\n## Likelihood Ratio Test (LRT)\n\nAs in standard regression modelling, we can also compare models using LRT. The `anova()` function will compute the LRT when two (nested) models are provided. In this case we compared a null (intercept-only) model with the model including the predictor.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# the null model\nfit0 <- rma(yi, vi, data = dat, method = \"REML\")\nanova(fit0, fit, refit = TRUE) # refit = TRUE because LRT with REML is not meaningful, using ML instead\n#> \n#>         df     AIC      BIC    AICc   logLik     LRT   pval       QE  tau^2 \n#> Full     3 45.0461  52.8617 45.2961 -19.5231                178.0054 0.0378 \n#> Reduced  2 99.7690 104.9793 99.8927 -47.8845 56.7228 <.0001 312.8327 0.1028 \n#>              R^2 \n#> Full             \n#> Reduced 63.1927%\n```\n:::\n\n\n## $R^2$\n\nThe $R^2$ value reported in the model output is not calculated as in standard regression analysis.\n\n$$\nR^2 = 1 - \\frac{\\tau^2_r}{\\tau^2}\n$$\n\nBasically is the percentage of heterogeneity reduction from the intercept-only model to the model including predictors.\n\nIn R:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n(1 - fit$tau2/fit0$tau2)*100\n#> [1] 62.07418\nfit$R2\n#> [1] 62.07418\n```\n:::\n\n\n## $R^2$\n\nDespite useful, the $R^2$ has some limitations:\n\n- @Lopez-Lopez2014-it showed that precise estimations require a large number of studies $k$ \n- Sometimes could results in negative values (usually truncated to zero)\n- Depends on the $\\tau^2$ estimator\n\nMore about $R^2$ and limitations can be found:\n\n- [https://www.metafor-project.org/doku.php/faq#for_mixed-effects_models_how_i](https://www.metafor-project.org/doku.php/faq#for_mixed-effects_models_how_i)\n- [https://www.metafor-project.org/doku.php/tips:ci_for_r2](https://www.metafor-project.org/doku.php/tips:ci_for_r2)\n\n## Numerical predictor\n\nThe same logic of simulating a meta-regression can be applied to numerical predictors. We still have $\\beta_0$ and $\\beta_1$ but $X$ has more levels. Let's simulate an impact of the average participants' age on the effect size.\n\n- $\\beta_0$ is the effect size when **age** is zero\n- $\\beta_1$ is the expected increase in the effect size for a unit increase in `age`\n\nHow we can choose plausible values for the parameters and parametrize the model correctly?\n\n## Parametrize $\\beta_0$\n\nThe intepretation (and the inference) of $\\beta_0$ is strongly dependent on the type of numerical predictor. An age of zero is (probably) empirically meaningless thus the  $\\beta_0$ is somehow not useful.\n\nWe can for example mean-center (or other type of centering procedure) moving the zero on a meaningful value.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nage <- 10:50 # the raw vector\nage0 <- age - mean(age) # centering on the mean\nage20 <- age - min(age) # centering on the minimum\n\nht(data.frame(age, age0, age20))\n#>    age age0 age20\n#> 1   10  -20     0\n#> 2   11  -19     1\n#> 3   12  -18     2\n#> 4   13  -17     3\n#> 5   14  -16     4\n#> 36  45   15    35\n#> 37  46   16    36\n#> 38  47   17    37\n#> 39  48   18    38\n#> 40  49   19    39\n#> 41  50   20    40\n```\n:::\n\n\n## Parametrize $\\beta_0$\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](meta-regression_files/figure-revealjs/unnamed-chunk-16-1.svg){fig-align='center' width=960}\n:::\n:::\n\n\n## Parametrize $\\beta_0$\n\nUsing different parametrizations will only affect the estimation (and the interpretation) of $\\beta_0$. Other parameters and indexes will be the same.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nk <- 100\nb0 <- 0.2 # effect size when age 0\nb1 <- 0.05 # slope (random for now)\nage <- round(runif(k, 20, 50)) # sampling from uniform distribution\ntau2r <- 0.05\nn <- 10 + rpois(k, 30 - 10)\n\nes <- b0 + b1 * age # raw\n\nage0 <- age - mean(age)\nage20 <- age - 20\n\ndat <- sim_studies(k = k, es = es, tau2 = tau2r, n1 = n, add = list(age = age, age0 = age0, age20 = age20))\n\nfit <- rma(yi, vi, mods = ~ age, data = dat)\nfit0 <- rma(yi, vi, mods = ~ age0, data = dat)\nfit20 <- rma(yi, vi, mods = ~ age20, data = dat)\n\n# showing the intercept\ncompare_rma(fit, fit0, fit20, extra_params = \"R2\") |> \n  round(3)\n#> fit: rma(yi = yi, vi = vi, mods = ~age, data = dat)\n#> fit0: rma(yi = yi, vi = vi, mods = ~age0, data = dat)\n#> fit20: rma(yi = yi, vi = vi, mods = ~age20, data = dat)\n#>                fit   fit0  fit20\n#> b (intrcpt)  0.392  1.969  1.275\n#> se           0.155  0.035  0.075\n#> zval         2.538 56.069 17.012\n#> pval         0.011  0.000  0.000\n#> ci.lb        0.089  1.900  1.128\n#> ci.ub        0.695  2.038  1.422\n#> R2          70.390 70.390 70.390\n#> I2          46.312 46.312 46.312\n#> tau2         0.056  0.056  0.056\n\n  # showing the intercept\ncompare_rma(fit, fit0, fit20, b = \"age\", extra_params = \"R2\") |> \n  round(3)\n#> fit: rma(yi = yi, vi = vi, mods = ~age, data = dat)\n#> fit0: rma(yi = yi, vi = vi, mods = ~age0, data = dat)\n#> fit20: rma(yi = yi, vi = vi, mods = ~age20, data = dat)\n#>            fit   fit0  fit20\n#> b (age)  0.044  0.044  0.044\n#> se       0.004  0.004  0.004\n#> zval    10.484 10.484 10.484\n#> pval     0.000  0.000  0.000\n#> ci.lb    0.036  0.036  0.036\n#> ci.ub    0.052  0.052  0.052\n#> R2      70.390 70.390 70.390\n#> I2      46.312 46.312 46.312\n#> tau2     0.056  0.056  0.056\n```\n:::\n\n\n## Choosing $\\beta_1$\n\nThe core of the model is $\\beta_1$ that is the **age** effect. Compared to the categorical case where $\\beta_1$ is just the standardized difference between two conditions, with numerical $X$ choosing a meaningful $\\beta_1$ is more challenging.\n\nTwo (maybe more) strategies:\n\n- simulating a lot of effects sizes fixing $beta_0$ and $\\beta_1$ and see the expected range of $y_i$\n- fixing a certain $R^2$ and choose the $\\beta_1$ producing that $R^2$\n- ...\n\n## $\\beta_1$ by simulations\n\nA strategy could be to simulate from the generative model a large number of studies and see the expected range of effect size [@Gelman2020-tg, Chapter 5 and p. 97]. A large number of unplausible values suggest that the chosen $\\beta_1$ is probably not appropriate.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nk <- 1e3\nn <- 30\ntau2 <- 0\nx <- runif(k, 20, 50) # age\nb0 <- 0.1\nb1 <- c(0.001, 0.05, 0.2)\nesl <- lapply(b1, function(b) b0 + b*x)\ndatl <- lapply(esl, function(es) sim_studies(k = k, es = es, tau2 = tau2, n1 = n, add = list(x = x)))\nnames(datl) <- b1\ndat <- dplyr::bind_rows(datl, .id = \"b1\")\nht(dat)\n#> \n#>         b1   id      yi     vi n1 n2        x \n#> 1    0.001    1  0.1367 0.0558 30 30 45.51315 \n#> 2    0.001    2  0.2215 0.0646 30 30 35.16359 \n#> 3    0.001    3 -0.0703 0.0562 30 30 23.13528 \n#> 4    0.001    4  0.3276 0.0691 30 30 39.33342 \n#> 5    0.001    5 -0.0707 0.0517 30 30 29.69147 \n#> 2995   0.2  995  3.9611 0.0802 30 30 20.96020 \n#> 2996   0.2  996  9.3788 0.0524 30 30 46.91735 \n#> 2997   0.2  997  8.5280 0.0557 30 30 42.45470 \n#> 2998   0.2  998  7.1164 0.0656 30 30 34.94071 \n#> 2999   0.2  999  4.9303 0.0514 30 30 24.54041 \n#> 3000   0.2 1000  7.7304 0.0743 30 30 37.36946\n```\n:::\n\n\n## $\\beta_1$ by simulations\n\nClearly given the limited range of the $x$ variable (`age`) some $\\beta_1$ values are implausible leading to effect sizes that are out of a meaningful empirical range.\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](meta-regression_files/figure-revealjs/unnamed-chunk-19-1.svg){fig-align='center' width=960}\n:::\n:::\n\n\n## Fixing $R^2$\n\nWe can use the approach by @Lopez-Lopez2014-it where predictors $x$ are sampled from a standard normal distribution (or standardized). $\\beta_1$ is calculated as $\\beta_1 = \\sqrt{\\tau^2 R^2}$ and the residual heterogeneity as $\\tau^2_r = \\tau^2 - \\beta^2_1$.\n\n\n::: {.cell layout-align=\"center\"}\n\n:::\n\n\n## Fixing $R^2$\n\nWe can check the simulation approach:\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nk <- 1e3\n1 - tau2r/tau2\n#> [1] 0.4\nx <- rnorm(k)\nes <- b0 + b1 * x\ndat <- sim_studies(k, es, tau2r, n1 = 1e3, add = list(x = x))\nfit <- rma(yi, vi, data = dat, mods = ~x)\nsummary(fit)\n#> \n#> Mixed-Effects Model (k = 1000; tau^2 estimator: REML)\n#> \n#>    logLik   deviance        AIC        BIC       AICc   \n#> -530.7334  1061.4667  1067.4667  1082.1840  1067.4909   \n#> \n#> tau^2 (estimated amount of residual heterogeneity):     0.1676 (SE = 0.0076)\n#> tau (square root of estimated tau^2 value):             0.4094\n#> I^2 (residual heterogeneity / unaccounted variability): 98.82%\n#> H^2 (unaccounted variability / sampling variability):   85.06\n#> R^2 (amount of heterogeneity accounted for):            39.90%\n#> \n#> Test for Residual Heterogeneity:\n#> QE(df = 998) = 84936.6718, p-val < .0001\n#> \n#> Test of Moderators (coefficient 2):\n#> QM(df = 1) = 656.5223, p-val < .0001\n#> \n#> Model Results:\n#> \n#>          estimate      se     zval    pval   ci.lb   ci.ub      \n#> intrcpt    0.1007  0.0130   7.7308  <.0001  0.0752  0.1262  *** \n#> x          0.3275  0.0128  25.6227  <.0001  0.3024  0.3525  *** \n#> \n#> ---\n#> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n:::\n\n\n## $R^2$ using simulations\n\nThe results from @Lopez-Lopez2014-it (and also our previous simulation) suggested that we need a large number of studies for precise $R^2$ estimations. Let's check using simulations the sampling distribution of $R^2$ using a plausible meta-analysis scenario.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nk <- 40 # number of studies\nn <- 10 + rpois(k, 40 - 10) # sample size\ntau2 <- 0.05 # tau ~ 0.22\nR2 <- 0.3\nb0 <- 0.1\nb1_2 <- tau2 * R2\nb1 <- sqrt(b1_2)\ntau2r <- tau2 - b1_2\nnsim <- 1e3\n\nR2i <- rep(NA, nsim)\n\nfor(i in 1:nsim){\n  x <- rnorm(k)\n  dat <- sim_studies(k = k, es = b0 + b1*x, tau2 = tau2r, n1 = n, add = list(x))\n  fit <- rma(yi, vi, data = dat, mods = ~x)\n  R2i[i] <- fit$R2\n}\n```\n:::\n\n\n## $R^2$ using simulations\n\nWe estimated the true $R^2$ correctly but there is a lot of uncertainty with a plausible meta-analysis scenario. There are a lot of meta-analysis also with lower $k$ worsening the results.\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](meta-regression_files/figure-revealjs/unnamed-chunk-23-1.svg){fig-align='center' width=960}\n:::\n:::\n\n\n## References <button class=\"btn\"><i class=\"fa fa-download\"></i><a href=\"data:text/x-bibtex;base64,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\" download=\"refs_to_download.bib\"> Download .bib file</a></button> {.refs}\n\n::: {#refs}\n:::",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}