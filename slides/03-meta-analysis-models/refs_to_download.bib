@MISC{Borenstein2009-mo,
  title = {Introduction to {Meta-Analysis}},
  author = {Borenstein, Michael and Hedges, Larry V and Higgins, Julian P T and
  Rothstein, Hannah R},
  date = {2009},
  doi = {10.1002/9780470743386},
  url = {http://dx.doi.org/10.1002/9780470743386},
  keywords = {MA Unconscious WM}
}

@ARTICLE{Langan2017-zn,
  title = {Comparative performance of heterogeneity variance estimators in
  meta-analysis: a review of simulation studies},
  author = {Langan, Dean and Higgins, Julian P T and Simmonds, Mark},
  journaltitle = {Research synthesis methods},
  publisher = {John Wiley \& Sons, Ltd},
  volume = {8},
  issue = {2},
  pages = {181-198},
  date = {2017-06},
  doi = {10.1002/jrsm.1198},
  pmid = {27060925},
  issn = {1759-2879,1759-2887},
  abstract = {Random-effects meta-analysis methods include an estimate of
  between-study heterogeneity variance. We present a systematic review of
  simulation studies comparing the performance of different estimation methods
  for this parameter. We summarise the performance of methods in relation to
  estimation of heterogeneity and of the overall effect estimate, and of
  confidence intervals for the latter. Among the twelve included simulation
  studies, the DerSimonian and Laird method was most commonly evaluated. This
  estimate is negatively biased when heterogeneity is moderate to high and
  therefore most studies recommended alternatives. The Paule-Mandel method was
  recommended by three studies: it is simple to implement, is less biased than
  DerSimonian and Laird and performs well in meta-analyses with dichotomous and
  continuous outcomes. In many of the included simulation studies, results were
  based on data that do not represent meta-analyses observed in practice, and
  only small selections of methods were compared. Furthermore, potential
  conflicts of interest were present when authors of novel methods interpreted
  their results. On the basis of current evidence, we provisionally recommend
  the Paule-Mandel method for estimating the heterogeneity variance, and using
  this estimate to calculate the mean effect and its 95\% confidence interval.
  However, further simulation studies are required to draw firm conclusions.
  Copyright © 2016 John Wiley \& Sons, Ltd.},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/jrsm.1198},
  keywords = {DerSimonian-Laird; heterogeneity; meta-analysis; random effects;
  simulation},
  language = {en}
}

@ARTICLE{Higgins2002-fh,
  title = {Quantifying heterogeneity in a meta-analysis},
  author = {Higgins, Julian P T and Thompson, Simon G},
  journaltitle = {Statistics in medicine},
  volume = {21},
  issue = {11},
  pages = {1539-1558},
  date = {2002-06-15},
  doi = {10.1002/sim.1186},
  pmid = {12111919},
  issn = {0277-6715},
  abstract = {The extent of heterogeneity in a meta-analysis partly determines
  the difficulty in drawing overall conclusions. This extent may be measured by
  estimating a between-study variance, but interpretation is then specific to a
  particular treatment effect metric. A test for the existence of heterogeneity
  exists, but depends on the number of studies in the meta-analysis. We develop
  measures of the impact of heterogeneity on a meta-analysis, from mathematical
  criteria, that are independent of the number of studies and the treatment
  effect metric. We derive and propose three suitable statistics: H is the
  square root of the chi2 heterogeneity statistic divided by its degrees of
  freedom; R is the ratio of the standard error of the underlying mean from a
  random effects meta-analysis to the standard error of a fixed effect
  meta-analytic estimate, and I2 is a transformation of (H) that describes the
  proportion of total variation in study estimates that is due to heterogeneity.
  We discuss interpretation, interval estimates and other properties of these
  measures and examine them in five example data sets showing different amounts
  of heterogeneity. We conclude that H and I2, which can usually be calculated
  for published meta-analyses, are particularly useful summaries of the impact
  of heterogeneity. One or both should be presented in published meta-analyses
  in preference to the test for heterogeneity.},
  url = {http://dx.doi.org/10.1002/sim.1186},
  language = {en}
}

@ARTICLE{Hedges2019-ry,
  title = {Statistical analyses for studying replication: Meta-analytic
  perspectives},
  author = {Hedges, Larry V and Schauer, Jacob M},
  journaltitle = {Psychological methods},
  publisher = {American Psychological Association (APA)},
  volume = {24},
  issue = {5},
  pages = {557-570},
  date = {2019-10},
  doi = {10.1037/met0000189},
  pmid = {30070547},
  issn = {1082-989X,1939-1463},
  abstract = {Formal empirical assessments of replication have recently become
  more prominent in several areas of science, including psychology. These
  assessments have used different statistical approaches to determine if a
  finding has been replicated. The purpose of this article is to provide several
  alternative conceptual frameworks that lead to different statistical analyses
  to test hypotheses about replication. All of these analyses are based on
  statistical methods used in meta-analysis. The differences among the methods
  described involve whether the burden of proof is placed on replication or
  nonreplication, whether replication is exact or allows for a small amount of
  "negligible heterogeneity," and whether the studies observed are assumed to be
  fixed (constituting the entire body of relevant evidence) or are a sample from
  a universe of possibly relevant studies. The statistical power of each of
  these tests is computed and shown to be low in many cases, raising issues of
  the interpretability of tests for replication. (PsycINFO Database Record (c)
  2019 APA, all rights reserved).},
  url = {http://dx.doi.org/10.1037/met0000189},
  file = {Hedges and Schauer 2019 - Statistical analyses for studying replication - Meta-analytic perspectives.pdf},
  keywords = {replication-methods},
  language = {en}
}

@ARTICLE{Riley2011-hp,
  title = {Interpretation of random effects meta-analyses},
  author = {Riley, Richard D and Higgins, Julian P T and Deeks, Jonathan J},
  journaltitle = {BMJ},
  volume = {342},
  pages = {d549},
  date = {2011-02-10},
  doi = {10.1136/bmj.d549},
  pmid = {21310794},
  issn = {0959-8138,1756-1833},
  url = {http://dx.doi.org/10.1136/bmj.d549},
  keywords = {MA Unconscious WM},
  language = {en}
}

@ARTICLE{IntHout2016-sz,
  title = {Plea for routinely presenting prediction intervals in meta-analysis},
  author = {IntHout, Joanna and Ioannidis, John P A and Rovers, Maroeska M and
  Goeman, Jelle J},
  journaltitle = {BMJ open},
  volume = {6},
  issue = {7},
  pages = {e010247},
  date = {2016-07-12},
  doi = {10.1136/bmjopen-2015-010247},
  pmc = {PMC4947751},
  pmid = {27406637},
  issn = {2044-6055},
  abstract = {OBJECTIVES: Evaluating the variation in the strength of the effect
  across studies is a key feature of meta-analyses. This variability is
  reflected by measures like τ(2) or I(2), but their clinical interpretation is
  not straightforward. A prediction interval is less complicated: it presents
  the expected range of true effects in similar studies. We aimed to show the
  advantages of having the prediction interval routinely reported in
  meta-analyses. DESIGN: We show how the prediction interval can help understand
  the uncertainty about whether an intervention works or not. To evaluate the
  implications of using this interval to interpret the results, we selected the
  first meta-analysis per intervention review of the Cochrane Database of
  Systematic Reviews Issues 2009-2013 with a dichotomous (n=2009) or continuous
  (n=1254) outcome, and generated 95\% prediction intervals for them. RESULTS:
  In 72.4\% of 479 statistically significant (random-effects p0), the 95\%
  prediction interval suggested that the intervention effect could be null or
  even be in the opposite direction. In 20.3\% of those 479 meta-analyses, the
  prediction interval showed that the effect could be completely opposite to the
  point estimate of the meta-analysis. We demonstrate also how the prediction
  interval can be used to calculate the probability that a new trial will show a
  negative effect and to improve the calculations of the power of a new trial.
  CONCLUSIONS: The prediction interval reflects the variation in treatment
  effects over different settings, including what effect is to be expected in
  future patients, such as the patients that a clinician is interested to treat.
  Prediction intervals should be routinely reported to allow more informative
  inferences in meta-analyses.},
  url = {http://dx.doi.org/10.1136/bmjopen-2015-010247},
  keywords = {Clinical trial; Cochrane Database of Systematic Reviews;
  Heterogeneity; Meta-analysis; Prediction interval; Random effects;MA
  Unconscious WM;Bayesian Statistics},
  language = {en}
}

@ARTICLE{Brannick2019-hv,
  title = {Bias and precision of alternate estimators in meta-analysis: Benefits
  of blending Schmidt-Hunter and Hedges approaches},
  author = {Brannick, Michael T and Potter, Sean M and Benitez, Bryan and
  Morris, Scott B},
  journaltitle = {Organizational research methods},
  publisher = {SAGE Publications},
  volume = {22},
  issue = {2},
  pages = {490-514},
  date = {2019-04},
  doi = {10.1177/1094428117741966},
  issn = {1094-4281,1552-7425},
  abstract = {We describe a new estimator (labeled Morris) for meta-analysis.
  The Morris estimator combines elements of both the Schmidt-Hunter and Hedges
  estimators. The new estimator is compared to (a) the Schmidt-Hunter estimator,
  (b) the Schmidt-Hunter estimator with variance correction for the number of
  studies (“ k correction”), (c) the Hedges random-effects estimator, and (d)
  the Bonett unit weights estimator in a Monte Carlo simulation. The simulation
  was designed to represent realistic conditions faced by researchers, including
  population random-effects distributions, numbers of studies, and skewed sample
  size distributions. The simulation was used to evaluate the estimators with
  respect to bias, coverage of the 95\% confidence interval of the mean, and
  root mean square error of estimates of the population mean. We also evaluated
  the quality of credibility intervals. Overall, the new estimator provides
  better coverage and slightly better credibility values than other commonly
  used methods. Thus it has advantages of both commonly used approaches without
  the apparent disadvantages. The new estimator can be implemented easily with
  existing software; software used in the study is available online, and an
  example is included in the appendix in the Supplemental Material available
  online.},
  url = {https://journals.sagepub.com/doi/abs/10.1177/1094428117741966},
  language = {en}
}

@ARTICLE{Viechtbauer2005-zt,
  title = {Bias and efficiency of meta-analytic variance estimators in the
  random-effects model},
  author = {Viechtbauer, Wolfgang},
  journaltitle = {Journal of educational and behavioral statistics: a quarterly
  publication sponsored by the American Educational Research Association and the
  American Statistical Association},
  publisher = {American Educational Research Association (AERA)},
  volume = {30},
  issue = {3},
  pages = {261-293},
  date = {2005-09},
  doi = {10.3102/10769986030003261},
  issn = {1076-9986,1935-1054},
  abstract = {The meta-analytic random effects model assumes that the
  variability in effect size estimates drawn from a set of studies can be
  decomposed into two parts: heterogeneity due to random population effects and
  sampling variance. In this context, the usual goal is to estimate the central
  tendency and the amount of heterogeneity in the population effect sizes. The
  amount of heterogeneity in a set of effect sizes has implications regarding
  the interpretation of the meta-analytic findings and often serves as an
  indicator for the presence of potential moderator variables. Five population
  heterogeneity estimators were compared in this article analytically and via
  Monte Carlo simulations with respect to their bias and efficiency.},
  url = {https://scholar.google.com/citations?view_op=view_citation&hl=en&user=J89RXJkAAAAJ&citation_for_view=J89RXJkAAAAJ:qjMakFHDy7sC},
  language = {en}
}

@BOOK{Harrer2021-go,
  title = {Doing meta-analysis with R: A hands-on guide},
  author = {Harrer, Mathias and Cuijpers, Pim and Furukawa, Toshi and Ebert,
  David},
  publisher = {CRC Press},
  location = {London, England},
  edition = {1st},
  date = {2021-09-13},
  pagetotal = {474},
  isbn = {9780367610074},
  language = {en}
}

